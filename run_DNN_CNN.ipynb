{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_DNN_CNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNFwJxGw+8CAsqHzQQ5y5jn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mk_C71IGGRS_","colab_type":"text"},"source":["This script is used to fun DNN and CNN model in google colab and do 5-fold cross validation.\n","Since typically a deep learning model would take huge time to train,we utilize colan free GPU to speed up. Meanwhile, a trained keras model is easy to move to R environment."]},{"cell_type":"code","metadata":{"id":"-82MUyXVzPsG","colab_type":"code","outputId":"507be9f9-3920-48ee-8e8a-f035d2e7ca36","executionInfo":{"status":"ok","timestamp":1586905660232,"user_tz":300,"elapsed":22098,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MolxgLtpzSRA","colab_type":"code","outputId":"dda91d8d-8ce9-4d17-a2a7-4b9a02bb68da","executionInfo":{"status":"ok","timestamp":1586905662448,"user_tz":300,"elapsed":1698,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/ESE529-project\") \n","os.listdir()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['final_train_data.RData',\n"," 'train_price.RData',\n"," 'true_price.RData',\n"," '__pycache__',\n"," 'utils.py',\n"," 'DNN (1).py',\n"," 'dnn_model1.h5',\n"," 'run_keras_model.ipynb']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Sz82gTbB050Q","colab_type":"code","outputId":"f0b55da5-0410-4c6a-812e-9159cac8bf8b","executionInfo":{"status":"ok","timestamp":1586905664378,"user_tz":300,"elapsed":1288,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["#import data from drive\n","import numpy as np\n","import pandas as pd\n","import rpy2.robjects as robjects\n","from rpy2.robjects import pandas2ri\n","pandas2ri.activate()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n","  from pandas.core.index import Index as PandasIndex\n","/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n","  warnings.warn('pandas >= 1.0 is not supported.')\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Zdb3cvHr07fc","colab_type":"code","colab":{}},"source":["robjects.r.load('final_train_data.RData')\n","final_train_data = robjects.r['final_train_data']\n","final_train_data=np.array(final_train_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKZv-r10GjQ7","colab_type":"code","outputId":"3c557507-1dab-4200-ba9f-c7251c09fa14","executionInfo":{"status":"ok","timestamp":1586578611112,"user_tz":300,"elapsed":1205,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["final_train_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1481661, 188)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"-kJyXuwH3-js","colab_type":"code","colab":{}},"source":["robjects.r.load('true_price.RData')\n","true_price = robjects.r['true_price']\n","true_price=np.array(true_price)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjnk6ghyWRmp","colab_type":"code","colab":{}},"source":["train_price=np.log(true_price+1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRECC5GS2l8i","colab_type":"code","outputId":"a2676daa-728d-47b4-9dd0-48701e4258be","executionInfo":{"status":"ok","timestamp":1586906070053,"user_tz":300,"elapsed":9028,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Seed value\n","# Apparently you may use different seed values at each stage\n","seed_value= 123\n","\n","# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n","import os\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","\n","# 2. Set the `python` built-in pseudo-random generator at a fixed value\n","import random\n","random.seed(seed_value)\n","\n","# 3. Set the `numpy` pseudo-random generator at a fixed value\n","import numpy as np\n","np.random.seed(seed_value)\n","\n","# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n","import tensorflow as tf\n","tf.random.set_seed(seed_value)\n","# for later versions: \n","# tf.compat.v1.set_random_seed(seed_value)\n","\n","# 5. Configure a new global `tensorflow` session\n","from keras import backend as K\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3yBEgbbsC0ob","colab_type":"code","colab":{}},"source":["import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import Input,Dense,BatchNormalization,Activation,Conv1D,\\\n","    Flatten,Reshape,Dropout,concatenate,MaxPooling1D,add\n","from tensorflow.keras import Model\n","from tensorflow.keras import regularizers\n","\n","#dnn model function\n","def DNN(input_dim,layer_list,activation=\"relu\",dropout=0.2):\n","    input=Input((input_dim,))\n","    for i in range(len(layer_list)):\n","        if i==0:\n","            dense=Dense(layer_list[i],activation=activation,\n","                        kernel_regularizer=regularizers.l2(0.001))(input)\n","            dense=BatchNormalization()(dense)\n","            dense=Activation(activation)(dense)\n","            if dropout>0:\n","                dense=Dropout(dropout)(dense)\n","        else:\n","            dense=Dense(layer_list[i],activation=activation,\n","                        kernel_regularizer=regularizers.l2(0.001))(dense)\n","            dense=BatchNormalization()(dense)\n","            dense=Activation(activation)(dense)\n","            if dropout>0:\n","                dense=Dropout(dropout)(dense)\n","    output=Dense(1)(dense)\n","    DNN_model=Model(input,output)\n","    return DNN_model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Awz-vC8MpmFW","colab_type":"code","colab":{}},"source":["#dnn modle with residual \n","def DNN_residual(input_dim,dropout=0.2):\n","     input=Input((input_dim,))\n","     #feature 1\n","     dense1_input=Dense(256,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(input)\n","     dense1=Dense(512,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(dense1_input)\n","     dense1=Dense(1024,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(dense1)\n","     dense1=Dense(256,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(dense1)\n","     dense1=add([dense1_input,dense1])\n","     dense1=BatchNormalization()(dense1)\n","     dense1=Activation(\"relu\")(dense1)\n","     dense1=Dropout(dropout)(dense1)\n","\n","    #feature 2\n","     dense2_input=Dense(512,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(input)\n","     dense2=Dense(1024,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(dense2_input)\n","     dense2=Dense(2048,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(dense2)\n","     dense2=Dense(512,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(dense2)\n","     dense2=add([dense2_input,dense2])\n","     dense2=BatchNormalization()(dense2)\n","     dense2=Activation(\"relu\")(dense2)\n","     dense2=Dropout(dropout)(dense2)\n","\n","     final_dense=concatenate([dense1,dense2])\n","     final_dense=Dense(256,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))(final_dense)\n","     final_dense=Dropout(dropout)(final_dense)\n","     final_dense=Dense(32)(final_dense)\n","\n","     dnn_residual=Model(input,final_dense)\n","     return dnn_residual"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6Izk_GANhas","colab_type":"code","colab":{}},"source":["#inception module\n","def inception(filter_size):\n","\n","    def f(input_layer):\n","        inception1=Conv1D(filter_size,1,padding=\"same\",activation=\"relu\")(input_layer)\n","\n","        inception2=Conv1D(filter_size,1,padding=\"same\",activation=\"relu\")(input_layer)\n","        inception2=Conv1D(filter_size,3,padding=\"same\",activation=\"relu\")(inception2)\n","\n","        inception3=Conv1D(filter_size,1,padding=\"same\",activation=\"relu\")(input_layer)\n","        inception3=Conv1D(filter_size,3,padding=\"same\",activation=\"relu\")(inception3)\n","        inception3=Conv1D(filter_size,3,padding=\"same\",activation=\"relu\")(inception3)\n","\n","        inception4=MaxPooling1D(padding=\"same\",strides=1)(input_layer)\n","        inception4=Conv1D(filter_size,3,padding=\"same\",activation=\"relu\")(inception4)\n","        concat=concatenate([inception1,inception2,inception3,inception4],axis=-1)\n","        concat=Conv1D(filter_size,1,padding=\"same\",activation=\"relu\")(concat)\n","\n","        output_layer=add([input_layer,concat])\n","        return output_layer\n","    return f\n","\n","#cnn model function\n","def CNN(input_dim1,input_dim2,filter_list1,dropout=0.2,reg=0.0001):\n","    catgorical_input=Input((input_dim1,))\n","    catgorical_dense=Dense(256,activation=\"relu\")(catgorical_input)\n","    catgorical_dense=Dense(512,activation=\"relu\")(catgorical_dense)\n","\n","    text_input=Input((input_dim2,))\n","    text_reshape=Reshape((input_dim2,1))(text_input)\n","    for i in range(len(filter_list1)):\n","        if i == 0:\n","\n","            text_conv = Conv1D(filter_list1[i], 5, padding=\"same\", activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(text_reshape)\n","        else:\n","            text_conv = Conv1D(filter_list1[i], 5, padding=\"same\", activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(text_conv)\n","        text_conv = inception(filter_list1[i])(text_conv)\n","        text_conv = BatchNormalization()(text_conv)\n","        text_conv = Activation(\"relu\")(text_conv)\n","        text_conv = Dropout(dropout)(text_conv)\n","\n","    text_flatten=Flatten()(text_conv)\n","    print(K.int_shape(text_flatten))\n","    concat=concatenate([catgorical_dense,text_flatten])\n","    \n","    new_shape=K.int_shape(concat)[1]\n","    concat=Reshape((new_shape,1))(concat)\n","    for j in range(len(filter_list2)):\n","        if j == 0:\n","            conv = Conv1D(filter_list2[j], 5, padding=\"same\", activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(concat)\n","        else:\n","            conv = Conv1D(filter_list2[j], 5, padding=\"same\", activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(conv)\n","        conv = inception(filter_list2[j])(conv)\n","        conv = BatchNormalization()(conv)\n","        conv = Activation(\"relu\")(conv)\n","        conv = Dropout(dropout)(conv)\n","    final_dense=Flatten()(conv)\n","    \n","    final_dense=Dense(2048,activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(final_dense)\n","    final_dense=Dense(1024,activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(final_dense)\n","    final_dense=Dense(256,activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(final_dense)\n","    final_dense=Dense(64,activation=\"relu\",kernel_regularizer=regularizers.l2(reg))(final_dense)\n","    output=Dense(1)(final_dense)\n","\n","    CNN_model=Model([catgorical_input,text_input],output)\n","    return CNN_model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"USfrOebLDAcI","colab_type":"code","colab":{}},"source":["def mse(y_pre,y_tr):\n","    original_y_pre=np.exp(y_pre)-1\n","    num_sample=y_pre.shape[0]\n","    mse_result=np.sum(np.square(original_y_pre-y_tr))/num_sample\n","    return mse_result\n","\n","def rmsle(y_pre,y_tr):\n","    nat_y_tr=np.log(y_tr+1)\n","    num_sample=y_pre.shape[0]\n","    rmsle_result=np.sqrt(np.sum(np.square(y_pre-nat_y_tr))/num_sample)\n","    return rmsle_result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXl8Qi4SDF6A","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dFGBhosDt4T","colab_type":"code","colab":{}},"source":["#split train and test\n","train_x,test_x,train_y,test_y,train_true_y,test_true_y=train_test_split(final_train_data,train_price,true_price,test_size=0.3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W5CmaSnxJxDJ","colab_type":"code","outputId":"10320776-4128-4b4a-ee0c-77c9ae7783fc","executionInfo":{"status":"ok","timestamp":1586906079065,"user_tz":300,"elapsed":3775,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#clear memory \n","del final_train_data\n","import gc\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"4VmPFUvxDdxt","colab_type":"code","colab":{}},"source":["#since colab only have limited memory, we manually do cross validation\n","kfold = KFold(n_splits=5, shuffle=True, random_state=seed_value)\n","train_mse_list=[]\n","val_mse_list=[]\n","train_rmsle_list=[]\n","val_rmsle_list=[]\n","index_list=list(kfold.split(train_x,train_y))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mw_eDAo9-grO","colab_type":"code","outputId":"1ee0b63f-ad03-4b38-9955-edcd0744a410","executionInfo":{"status":"error","timestamp":1586918398525,"user_tz":300,"elapsed":1288682,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#here we only retain one fold for demonstrating.\n","train,val=index_list[0]\n","dnn_model=DNN(188,[512,1024,2048,512,256,64],dropout=0.2)\n","dnn_model.compile(loss=\"mse\", \n","                optimizer='adam',\n","                metrics=['mse'])\n","dnn_model.fit(train_x[train,:],train_y[train],batch_size=2048,epochs=25,validation_data=(train_x[val,:],train_y[val]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","406/406 [==============================] - 8s 19ms/step - loss: 5.0957 - mse: 1.8070 - val_loss: 3.6408 - val_mse: 0.9367\n","Epoch 2/200\n","406/406 [==============================] - 7s 18ms/step - loss: 2.7987 - mse: 0.7119 - val_loss: 2.0206 - val_mse: 0.4935\n","Epoch 3/200\n","406/406 [==============================] - 7s 18ms/step - loss: 1.6818 - mse: 0.5613 - val_loss: 1.2288 - val_mse: 0.4434\n","Epoch 4/200\n","406/406 [==============================] - 7s 18ms/step - loss: 1.0645 - mse: 0.4942 - val_loss: 0.8383 - val_mse: 0.4400\n","Epoch 5/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.7467 - mse: 0.4538 - val_loss: 0.6028 - val_mse: 0.3930\n","Epoch 6/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.5883 - mse: 0.4284 - val_loss: 0.5038 - val_mse: 0.3839\n","Epoch 7/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.5085 - mse: 0.4121 - val_loss: 0.4504 - val_mse: 0.3729\n","Epoch 8/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4695 - mse: 0.4036 - val_loss: 0.4053 - val_mse: 0.3493\n","Epoch 9/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4471 - mse: 0.3967 - val_loss: 0.4023 - val_mse: 0.3560\n","Epoch 10/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4361 - mse: 0.3921 - val_loss: 0.4015 - val_mse: 0.3597\n","Epoch 11/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4285 - mse: 0.3876 - val_loss: 0.3955 - val_mse: 0.3560\n","Epoch 12/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4244 - mse: 0.3836 - val_loss: 0.4026 - val_mse: 0.3643\n","Epoch 13/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4176 - mse: 0.3791 - val_loss: 0.4250 - val_mse: 0.3872\n","Epoch 14/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4133 - mse: 0.3756 - val_loss: 0.4304 - val_mse: 0.3921\n","Epoch 15/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4098 - mse: 0.3720 - val_loss: 0.4055 - val_mse: 0.3681\n","Epoch 16/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4059 - mse: 0.3683 - val_loss: 0.4438 - val_mse: 0.3988\n","Epoch 17/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.4025 - mse: 0.3657 - val_loss: 0.4010 - val_mse: 0.3661\n","Epoch 18/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3984 - mse: 0.3625 - val_loss: 0.3777 - val_mse: 0.3429\n","Epoch 19/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3941 - mse: 0.3594 - val_loss: 0.3801 - val_mse: 0.3463\n","Epoch 20/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3915 - mse: 0.3573 - val_loss: 0.3844 - val_mse: 0.3504\n","Epoch 21/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3893 - mse: 0.3557 - val_loss: 0.3843 - val_mse: 0.3518\n","Epoch 22/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3849 - mse: 0.3529 - val_loss: 0.3760 - val_mse: 0.3460\n","Epoch 23/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3806 - mse: 0.3508 - val_loss: 0.3715 - val_mse: 0.3420\n","Epoch 24/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3785 - mse: 0.3497 - val_loss: 0.3663 - val_mse: 0.3385\n","Epoch 25/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3769 - mse: 0.3486 - val_loss: 0.3683 - val_mse: 0.3405\n","Epoch 26/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3763 - mse: 0.3485 - val_loss: 0.3695 - val_mse: 0.3425\n","Epoch 27/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3754 - mse: 0.3482 - val_loss: 0.3666 - val_mse: 0.3403\n","Epoch 28/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3749 - mse: 0.3480 - val_loss: 0.3680 - val_mse: 0.3412\n","Epoch 29/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3741 - mse: 0.3477 - val_loss: 0.3658 - val_mse: 0.3400\n","Epoch 30/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3732 - mse: 0.3474 - val_loss: 0.3658 - val_mse: 0.3408\n","Epoch 31/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3727 - mse: 0.3473 - val_loss: 0.3687 - val_mse: 0.3434\n","Epoch 32/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3725 - mse: 0.3471 - val_loss: 0.3766 - val_mse: 0.3501\n","Epoch 33/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3722 - mse: 0.3472 - val_loss: 0.3682 - val_mse: 0.3434\n","Epoch 34/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3712 - mse: 0.3464 - val_loss: 0.3623 - val_mse: 0.3374\n","Epoch 35/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3706 - mse: 0.3463 - val_loss: 0.3639 - val_mse: 0.3399\n","Epoch 36/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3710 - mse: 0.3467 - val_loss: 0.3704 - val_mse: 0.3464\n","Epoch 37/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3708 - mse: 0.3466 - val_loss: 0.3610 - val_mse: 0.3368\n","Epoch 38/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3709 - mse: 0.3466 - val_loss: 0.3602 - val_mse: 0.3363\n","Epoch 39/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3699 - mse: 0.3461 - val_loss: 0.3644 - val_mse: 0.3408\n","Epoch 40/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3702 - mse: 0.3467 - val_loss: 0.3670 - val_mse: 0.3437\n","Epoch 41/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3697 - mse: 0.3464 - val_loss: 0.3640 - val_mse: 0.3410\n","Epoch 42/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3699 - mse: 0.3467 - val_loss: 0.3616 - val_mse: 0.3386\n","Epoch 43/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3702 - mse: 0.3467 - val_loss: 0.3625 - val_mse: 0.3394\n","Epoch 44/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3698 - mse: 0.3466 - val_loss: 0.3617 - val_mse: 0.3385\n","Epoch 45/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3702 - mse: 0.3472 - val_loss: 0.3598 - val_mse: 0.3370\n","Epoch 46/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3691 - mse: 0.3460 - val_loss: 0.3679 - val_mse: 0.3454\n","Epoch 47/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3692 - mse: 0.3463 - val_loss: 0.3601 - val_mse: 0.3374\n","Epoch 48/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3689 - mse: 0.3460 - val_loss: 0.3615 - val_mse: 0.3390\n","Epoch 49/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3687 - mse: 0.3463 - val_loss: 0.3602 - val_mse: 0.3378\n","Epoch 50/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3683 - mse: 0.3460 - val_loss: 0.3672 - val_mse: 0.3450\n","Epoch 51/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3687 - mse: 0.3463 - val_loss: 0.3640 - val_mse: 0.3416\n","Epoch 52/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3684 - mse: 0.3460 - val_loss: 0.3578 - val_mse: 0.3358\n","Epoch 53/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3676 - mse: 0.3456 - val_loss: 0.3616 - val_mse: 0.3395\n","Epoch 54/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3673 - mse: 0.3455 - val_loss: 0.3583 - val_mse: 0.3365\n","Epoch 55/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3680 - mse: 0.3460 - val_loss: 0.3654 - val_mse: 0.3438\n","Epoch 56/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3683 - mse: 0.3463 - val_loss: 0.3572 - val_mse: 0.3353\n","Epoch 57/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3674 - mse: 0.3457 - val_loss: 0.3587 - val_mse: 0.3367\n","Epoch 58/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3677 - mse: 0.3458 - val_loss: 0.3609 - val_mse: 0.3393\n","Epoch 59/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3677 - mse: 0.3459 - val_loss: 0.3574 - val_mse: 0.3356\n","Epoch 60/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3677 - mse: 0.3459 - val_loss: 0.3563 - val_mse: 0.3346\n","Epoch 61/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3674 - mse: 0.3455 - val_loss: 0.3606 - val_mse: 0.3392\n","Epoch 62/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3672 - mse: 0.3457 - val_loss: 0.3622 - val_mse: 0.3406\n","Epoch 63/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3669 - mse: 0.3455 - val_loss: 0.3561 - val_mse: 0.3346\n","Epoch 64/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3675 - mse: 0.3458 - val_loss: 0.3623 - val_mse: 0.3408\n","Epoch 65/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3674 - mse: 0.3459 - val_loss: 0.3584 - val_mse: 0.3375\n","Epoch 66/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3672 - mse: 0.3460 - val_loss: 0.3615 - val_mse: 0.3407\n","Epoch 67/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3674 - mse: 0.3463 - val_loss: 0.3599 - val_mse: 0.3384\n","Epoch 68/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3673 - mse: 0.3462 - val_loss: 0.3627 - val_mse: 0.3418\n","Epoch 69/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3671 - mse: 0.3460 - val_loss: 0.3595 - val_mse: 0.3376\n","Epoch 70/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3672 - mse: 0.3459 - val_loss: 0.3638 - val_mse: 0.3422\n","Epoch 71/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3671 - mse: 0.3458 - val_loss: 0.3587 - val_mse: 0.3379\n","Epoch 72/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3669 - mse: 0.3458 - val_loss: 0.3577 - val_mse: 0.3367\n","Epoch 73/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3665 - mse: 0.3453 - val_loss: 0.3554 - val_mse: 0.3347\n","Epoch 74/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3674 - mse: 0.3462 - val_loss: 0.3581 - val_mse: 0.3369\n","Epoch 75/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3669 - mse: 0.3458 - val_loss: 0.3572 - val_mse: 0.3365\n","Epoch 76/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3671 - mse: 0.3460 - val_loss: 0.3600 - val_mse: 0.3393\n","Epoch 77/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3666 - mse: 0.3457 - val_loss: 0.3557 - val_mse: 0.3350\n","Epoch 78/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3665 - mse: 0.3458 - val_loss: 0.3560 - val_mse: 0.3356\n","Epoch 79/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3665 - mse: 0.3459 - val_loss: 0.3682 - val_mse: 0.3476\n","Epoch 80/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3667 - mse: 0.3458 - val_loss: 0.3629 - val_mse: 0.3424\n","Epoch 81/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3667 - mse: 0.3458 - val_loss: 0.3596 - val_mse: 0.3390\n","Epoch 82/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3664 - mse: 0.3455 - val_loss: 0.3565 - val_mse: 0.3360\n","Epoch 83/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3661 - mse: 0.3454 - val_loss: 0.3584 - val_mse: 0.3379\n","Epoch 84/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3668 - mse: 0.3461 - val_loss: 0.3576 - val_mse: 0.3371\n","Epoch 85/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3665 - mse: 0.3458 - val_loss: 0.3568 - val_mse: 0.3366\n","Epoch 86/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3668 - mse: 0.3461 - val_loss: 0.3565 - val_mse: 0.3361\n","Epoch 87/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3663 - mse: 0.3455 - val_loss: 0.3586 - val_mse: 0.3382\n","Epoch 88/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3661 - mse: 0.3458 - val_loss: 0.3550 - val_mse: 0.3343\n","Epoch 89/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3660 - mse: 0.3455 - val_loss: 0.3636 - val_mse: 0.3434\n","Epoch 90/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3663 - mse: 0.3459 - val_loss: 0.3609 - val_mse: 0.3406\n","Epoch 91/200\n","406/406 [==============================] - 8s 18ms/step - loss: 0.3663 - mse: 0.3459 - val_loss: 0.3594 - val_mse: 0.3392\n","Epoch 92/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3660 - mse: 0.3456 - val_loss: 0.3662 - val_mse: 0.3458\n","Epoch 93/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3660 - mse: 0.3458 - val_loss: 0.3577 - val_mse: 0.3373\n","Epoch 94/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3659 - mse: 0.3458 - val_loss: 0.3558 - val_mse: 0.3356\n","Epoch 95/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3658 - mse: 0.3455 - val_loss: 0.3616 - val_mse: 0.3415\n","Epoch 96/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3660 - mse: 0.3458 - val_loss: 0.3590 - val_mse: 0.3384\n","Epoch 97/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3663 - mse: 0.3461 - val_loss: 0.3610 - val_mse: 0.3408\n","Epoch 98/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3664 - mse: 0.3460 - val_loss: 0.3551 - val_mse: 0.3346\n","Epoch 99/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3658 - mse: 0.3456 - val_loss: 0.3618 - val_mse: 0.3416\n","Epoch 100/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3659 - mse: 0.3455 - val_loss: 0.3548 - val_mse: 0.3344\n","Epoch 101/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3657 - mse: 0.3455 - val_loss: 0.3581 - val_mse: 0.3382\n","Epoch 102/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3661 - mse: 0.3457 - val_loss: 0.3534 - val_mse: 0.3334\n","Epoch 103/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3661 - mse: 0.3456 - val_loss: 0.3572 - val_mse: 0.3371\n","Epoch 104/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3454 - val_loss: 0.3580 - val_mse: 0.3377\n","Epoch 105/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3655 - mse: 0.3455 - val_loss: 0.3551 - val_mse: 0.3352\n","Epoch 106/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3659 - mse: 0.3458 - val_loss: 0.3598 - val_mse: 0.3396\n","Epoch 107/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3659 - mse: 0.3457 - val_loss: 0.3560 - val_mse: 0.3360\n","Epoch 108/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3660 - mse: 0.3458 - val_loss: 0.3720 - val_mse: 0.3522\n","Epoch 109/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3657 - mse: 0.3455 - val_loss: 0.3592 - val_mse: 0.3395\n","Epoch 110/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3664 - mse: 0.3463 - val_loss: 0.3581 - val_mse: 0.3381\n","Epoch 111/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3655 - mse: 0.3455 - val_loss: 0.3585 - val_mse: 0.3391\n","Epoch 112/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3652 - mse: 0.3454 - val_loss: 0.3559 - val_mse: 0.3362\n","Epoch 113/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3654 - mse: 0.3454 - val_loss: 0.3563 - val_mse: 0.3367\n","Epoch 114/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3458 - val_loss: 0.3537 - val_mse: 0.3339\n","Epoch 115/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3457 - val_loss: 0.3579 - val_mse: 0.3381\n","Epoch 116/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3659 - mse: 0.3460 - val_loss: 0.3552 - val_mse: 0.3353\n","Epoch 117/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3655 - mse: 0.3457 - val_loss: 0.3556 - val_mse: 0.3359\n","Epoch 118/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3652 - mse: 0.3454 - val_loss: 0.3647 - val_mse: 0.3447\n","Epoch 119/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3657 - mse: 0.3459 - val_loss: 0.3551 - val_mse: 0.3354\n","Epoch 120/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3654 - mse: 0.3456 - val_loss: 0.3546 - val_mse: 0.3347\n","Epoch 121/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3653 - mse: 0.3456 - val_loss: 0.3580 - val_mse: 0.3386\n","Epoch 122/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3652 - mse: 0.3456 - val_loss: 0.3633 - val_mse: 0.3437\n","Epoch 123/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3655 - mse: 0.3458 - val_loss: 0.3562 - val_mse: 0.3363\n","Epoch 124/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3456 - val_loss: 0.3602 - val_mse: 0.3403\n","Epoch 125/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3458 - val_loss: 0.3569 - val_mse: 0.3373\n","Epoch 126/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3459 - val_loss: 0.3638 - val_mse: 0.3444\n","Epoch 127/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3652 - mse: 0.3455 - val_loss: 0.3538 - val_mse: 0.3340\n","Epoch 128/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3653 - mse: 0.3456 - val_loss: 0.3631 - val_mse: 0.3433\n","Epoch 129/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3653 - mse: 0.3457 - val_loss: 0.3571 - val_mse: 0.3376\n","Epoch 130/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3657 - mse: 0.3460 - val_loss: 0.3612 - val_mse: 0.3419\n","Epoch 131/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3654 - mse: 0.3458 - val_loss: 0.3540 - val_mse: 0.3344\n","Epoch 132/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3651 - mse: 0.3456 - val_loss: 0.3540 - val_mse: 0.3345\n","Epoch 133/200\n","406/406 [==============================] - 8s 19ms/step - loss: 0.3649 - mse: 0.3455 - val_loss: 0.3563 - val_mse: 0.3370\n","Epoch 134/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3650 - mse: 0.3454 - val_loss: 0.3565 - val_mse: 0.3369\n","Epoch 135/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3648 - mse: 0.3452 - val_loss: 0.3567 - val_mse: 0.3372\n","Epoch 136/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3653 - mse: 0.3456 - val_loss: 0.3542 - val_mse: 0.3346\n","Epoch 137/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3651 - mse: 0.3455 - val_loss: 0.3617 - val_mse: 0.3419\n","Epoch 138/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3652 - mse: 0.3455 - val_loss: 0.3558 - val_mse: 0.3363\n","Epoch 139/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3651 - mse: 0.3458 - val_loss: 0.3539 - val_mse: 0.3346\n","Epoch 140/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3649 - mse: 0.3454 - val_loss: 0.3575 - val_mse: 0.3382\n","Epoch 141/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3650 - mse: 0.3455 - val_loss: 0.3533 - val_mse: 0.3341\n","Epoch 142/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3653 - mse: 0.3459 - val_loss: 0.3543 - val_mse: 0.3349\n","Epoch 143/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3657 - mse: 0.3461 - val_loss: 0.3701 - val_mse: 0.3503\n","Epoch 144/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3656 - mse: 0.3460 - val_loss: 0.3600 - val_mse: 0.3404\n","Epoch 145/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3649 - mse: 0.3456 - val_loss: 0.3552 - val_mse: 0.3357\n","Epoch 146/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3646 - mse: 0.3453 - val_loss: 0.3563 - val_mse: 0.3370\n","Epoch 147/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3650 - mse: 0.3456 - val_loss: 0.3581 - val_mse: 0.3389\n","Epoch 148/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3648 - mse: 0.3453 - val_loss: 0.3553 - val_mse: 0.3360\n","Epoch 149/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3649 - mse: 0.3455 - val_loss: 0.3536 - val_mse: 0.3346\n","Epoch 150/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3456 - val_loss: 0.3557 - val_mse: 0.3366\n","Epoch 151/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3457 - val_loss: 0.3542 - val_mse: 0.3352\n","Epoch 152/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3642 - mse: 0.3451 - val_loss: 0.3551 - val_mse: 0.3360\n","Epoch 153/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3456 - val_loss: 0.3602 - val_mse: 0.3413\n","Epoch 154/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3648 - mse: 0.3457 - val_loss: 0.3636 - val_mse: 0.3445\n","Epoch 155/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3652 - mse: 0.3460 - val_loss: 0.3542 - val_mse: 0.3351\n","Epoch 156/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3643 - mse: 0.3452 - val_loss: 0.3574 - val_mse: 0.3382\n","Epoch 157/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3456 - val_loss: 0.3576 - val_mse: 0.3385\n","Epoch 158/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3457 - val_loss: 0.3619 - val_mse: 0.3427\n","Epoch 159/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3642 - mse: 0.3452 - val_loss: 0.3540 - val_mse: 0.3350\n","Epoch 160/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3645 - mse: 0.3456 - val_loss: 0.3555 - val_mse: 0.3367\n","Epoch 161/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3643 - mse: 0.3455 - val_loss: 0.3603 - val_mse: 0.3414\n","Epoch 162/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3644 - mse: 0.3453 - val_loss: 0.3554 - val_mse: 0.3368\n","Epoch 163/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3456 - val_loss: 0.3613 - val_mse: 0.3423\n","Epoch 164/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3642 - mse: 0.3451 - val_loss: 0.3553 - val_mse: 0.3363\n","Epoch 165/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3643 - mse: 0.3455 - val_loss: 0.3579 - val_mse: 0.3389\n","Epoch 166/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3644 - mse: 0.3455 - val_loss: 0.3549 - val_mse: 0.3361\n","Epoch 167/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3645 - mse: 0.3457 - val_loss: 0.3543 - val_mse: 0.3351\n","Epoch 168/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3457 - val_loss: 0.3573 - val_mse: 0.3384\n","Epoch 169/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3647 - mse: 0.3457 - val_loss: 0.3545 - val_mse: 0.3355\n","Epoch 170/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3644 - mse: 0.3455 - val_loss: 0.3563 - val_mse: 0.3373\n","Epoch 171/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3648 - mse: 0.3460 - val_loss: 0.3557 - val_mse: 0.3369\n","Epoch 172/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3646 - mse: 0.3458 - val_loss: 0.3538 - val_mse: 0.3351\n","Epoch 173/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3640 - mse: 0.3453 - val_loss: 0.3572 - val_mse: 0.3383\n","Epoch 174/200\n","406/406 [==============================] - 7s 18ms/step - loss: 0.3648 - mse: 0.3461 - val_loss: 0.3567 - val_mse: 0.3378\n","Epoch 175/200\n","158/406 [==========>...................] - ETA: 4s - loss: 0.3658 - mse: 0.3469"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c477b8350863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 metrics=['mse'])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"61mhifRuIn0A","colab_type":"code","colab":{}},"source":["#since colab only have limited memory, we manually do cross validation\n","kfold = KFold(n_splits=5, shuffle=True, random_state=seed_value)\n","train_mse_list=[]\n","val_mse_list=[]\n","train_rmsle_list=[]\n","val_rmsle_list=[]\n","index_list=list(kfold.split(train_x,train_y))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1ddIwdPNL15","colab_type":"code","outputId":"0197a334-af2c-4be0-c10c-b468ba723c67","executionInfo":{"status":"ok","timestamp":1586914756121,"user_tz":300,"elapsed":428465,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","train,val=index_list[0]\n","cnn_model=CNN(132,56,[8,32,64],[4,8,16])\n","cnn_model.compile(loss='mse', \n","                optimizer='adam',\n","                metrics=['mse'])\n","cnn_model.fit([train_x[train,:132],train_x[train,132:]],train_y[train],batch_size=2048,epochs=200,validation_data=([train_x[val,:132],train_x[val,132:]],train_y[val]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 3584)\n","Epoch 1/200\n","406/406 [==============================] - 34s 84ms/step - loss: 2.0223 - mse: 1.5653 - val_loss: 0.8279 - val_mse: 0.4060\n","Epoch 2/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.7826 - mse: 0.3939 - val_loss: 0.7308 - val_mse: 0.3729\n","Epoch 3/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.7111 - mse: 0.3794 - val_loss: 0.6952 - val_mse: 0.3876\n","Epoch 4/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.6557 - mse: 0.3694 - val_loss: 0.6379 - val_mse: 0.3713\n","Epoch 5/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.6097 - mse: 0.3608 - val_loss: 0.5989 - val_mse: 0.3663\n","Epoch 6/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5712 - mse: 0.3535 - val_loss: 0.5786 - val_mse: 0.3744\n","Epoch 7/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5401 - mse: 0.3484 - val_loss: 0.5249 - val_mse: 0.3451\n","Epoch 8/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5131 - mse: 0.3441 - val_loss: 0.4964 - val_mse: 0.3376\n","Epoch 9/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4895 - mse: 0.3402 - val_loss: 0.4780 - val_mse: 0.3375\n","Epoch 10/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4688 - mse: 0.3367 - val_loss: 0.4503 - val_mse: 0.3260\n","Epoch 11/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.4512 - mse: 0.3341 - val_loss: 0.4363 - val_mse: 0.3262\n","Epoch 12/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4342 - mse: 0.3305 - val_loss: 0.4298 - val_mse: 0.3324\n","Epoch 13/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.4195 - mse: 0.3278 - val_loss: 0.4093 - val_mse: 0.3234\n","Epoch 14/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4061 - mse: 0.3252 - val_loss: 0.4159 - val_mse: 0.3400\n","Epoch 15/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3951 - mse: 0.3236 - val_loss: 0.3856 - val_mse: 0.3184\n","Epoch 16/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3838 - mse: 0.3207 - val_loss: 0.3859 - val_mse: 0.3263\n","Epoch 17/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3764 - mse: 0.3203 - val_loss: 0.3713 - val_mse: 0.3187\n","Epoch 18/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3677 - mse: 0.3180 - val_loss: 0.3657 - val_mse: 0.3193\n","Epoch 19/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3623 - mse: 0.3180 - val_loss: 0.3684 - val_mse: 0.3267\n","Epoch 20/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3553 - mse: 0.3158 - val_loss: 0.3499 - val_mse: 0.3127\n","Epoch 21/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3508 - mse: 0.3153 - val_loss: 0.3458 - val_mse: 0.3124\n","Epoch 22/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3456 - mse: 0.3135 - val_loss: 0.3431 - val_mse: 0.3127\n","Epoch 23/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3411 - mse: 0.3120 - val_loss: 0.3382 - val_mse: 0.3105\n","Epoch 24/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3382 - mse: 0.3116 - val_loss: 0.3511 - val_mse: 0.3254\n","Epoch 25/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3357 - mse: 0.3112 - val_loss: 0.3344 - val_mse: 0.3107\n","Epoch 26/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3325 - mse: 0.3096 - val_loss: 0.3298 - val_mse: 0.3076\n","Epoch 27/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3306 - mse: 0.3092 - val_loss: 0.3307 - val_mse: 0.3099\n","Epoch 28/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3283 - mse: 0.3080 - val_loss: 0.3358 - val_mse: 0.3162\n","Epoch 29/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3263 - mse: 0.3069 - val_loss: 0.3256 - val_mse: 0.3068\n","Epoch 30/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3245 - mse: 0.3060 - val_loss: 0.3238 - val_mse: 0.3059\n","Epoch 31/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3234 - mse: 0.3056 - val_loss: 0.3260 - val_mse: 0.3083\n","Epoch 32/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3217 - mse: 0.3043 - val_loss: 0.3210 - val_mse: 0.3042\n","Epoch 33/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3199 - mse: 0.3032 - val_loss: 0.3365 - val_mse: 0.3200\n","Epoch 34/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3221 - mse: 0.3054 - val_loss: 0.3218 - val_mse: 0.3056\n","Epoch 35/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3192 - mse: 0.3029 - val_loss: 0.3499 - val_mse: 0.3338\n","Epoch 36/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3192 - mse: 0.3030 - val_loss: 0.3206 - val_mse: 0.3046\n","Epoch 37/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3169 - mse: 0.3009 - val_loss: 0.3182 - val_mse: 0.3024\n","Epoch 38/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3171 - mse: 0.3010 - val_loss: 0.3223 - val_mse: 0.3065\n","Epoch 39/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3160 - mse: 0.3000 - val_loss: 0.3182 - val_mse: 0.3025\n","Epoch 40/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3155 - mse: 0.2997 - val_loss: 0.3184 - val_mse: 0.3027\n","Epoch 41/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3143 - mse: 0.2985 - val_loss: 0.3184 - val_mse: 0.3027\n","Epoch 42/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3139 - mse: 0.2982 - val_loss: 0.3170 - val_mse: 0.3014\n","Epoch 43/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3139 - mse: 0.2981 - val_loss: 0.3224 - val_mse: 0.3068\n","Epoch 44/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3132 - mse: 0.2974 - val_loss: 0.3179 - val_mse: 0.3022\n","Epoch 45/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3132 - mse: 0.2972 - val_loss: 0.3184 - val_mse: 0.3027\n","Epoch 46/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3127 - mse: 0.2966 - val_loss: 0.3161 - val_mse: 0.3004\n","Epoch 47/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3126 - mse: 0.2968 - val_loss: 0.3200 - val_mse: 0.3042\n","Epoch 48/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3117 - mse: 0.2958 - val_loss: 0.3182 - val_mse: 0.3024\n","Epoch 49/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3115 - mse: 0.2957 - val_loss: 0.3196 - val_mse: 0.3038\n","Epoch 50/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3110 - mse: 0.2950 - val_loss: 0.3175 - val_mse: 0.3016\n","Epoch 51/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3111 - mse: 0.2950 - val_loss: 0.3183 - val_mse: 0.3024\n","Epoch 52/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3102 - mse: 0.2941 - val_loss: 0.3168 - val_mse: 0.3008\n","Epoch 53/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3104 - mse: 0.2944 - val_loss: 0.3174 - val_mse: 0.3014\n","Epoch 54/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3098 - mse: 0.2938 - val_loss: 0.3172 - val_mse: 0.3012\n","Epoch 55/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3094 - mse: 0.2931 - val_loss: 0.3169 - val_mse: 0.3009\n","Epoch 56/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3095 - mse: 0.2933 - val_loss: 0.3195 - val_mse: 0.3035\n","Epoch 57/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3089 - mse: 0.2928 - val_loss: 0.3177 - val_mse: 0.3014\n","Epoch 58/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3085 - mse: 0.2920 - val_loss: 0.3190 - val_mse: 0.3028\n","Epoch 59/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3090 - mse: 0.2925 - val_loss: 0.3203 - val_mse: 0.3040\n","Epoch 60/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3083 - mse: 0.2918 - val_loss: 0.3159 - val_mse: 0.2996\n","Epoch 61/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3077 - mse: 0.2910 - val_loss: 0.3176 - val_mse: 0.3012\n","Epoch 62/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3082 - mse: 0.2919 - val_loss: 0.3187 - val_mse: 0.3022\n","Epoch 63/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3072 - mse: 0.2907 - val_loss: 0.3165 - val_mse: 0.3000\n","Epoch 64/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3071 - mse: 0.2903 - val_loss: 0.3191 - val_mse: 0.3026\n","Epoch 65/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3067 - mse: 0.2900 - val_loss: 0.3184 - val_mse: 0.3018\n","Epoch 66/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3068 - mse: 0.2901 - val_loss: 0.3169 - val_mse: 0.3003\n","Epoch 67/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3067 - mse: 0.2900 - val_loss: 0.3206 - val_mse: 0.3040\n","Epoch 68/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3063 - mse: 0.2896 - val_loss: 0.3160 - val_mse: 0.2994\n","Epoch 69/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3059 - mse: 0.2892 - val_loss: 0.3182 - val_mse: 0.3014\n","Epoch 70/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3059 - mse: 0.2890 - val_loss: 0.3205 - val_mse: 0.3037\n","Epoch 71/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3056 - mse: 0.2887 - val_loss: 0.3179 - val_mse: 0.3009\n","Epoch 72/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3056 - mse: 0.2887 - val_loss: 0.3194 - val_mse: 0.3025\n","Epoch 73/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3055 - mse: 0.2883 - val_loss: 0.3193 - val_mse: 0.3023\n","Epoch 74/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3049 - mse: 0.2878 - val_loss: 0.3187 - val_mse: 0.3016\n","Epoch 75/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3051 - mse: 0.2879 - val_loss: 0.3154 - val_mse: 0.2983\n","Epoch 76/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3051 - mse: 0.2878 - val_loss: 0.3154 - val_mse: 0.2983\n","Epoch 77/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3047 - mse: 0.2874 - val_loss: 0.3165 - val_mse: 0.2993\n","Epoch 78/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3040 - mse: 0.2868 - val_loss: 0.3180 - val_mse: 0.3006\n","Epoch 79/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3043 - mse: 0.2868 - val_loss: 0.3218 - val_mse: 0.3043\n","Epoch 80/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3043 - mse: 0.2867 - val_loss: 0.3198 - val_mse: 0.3025\n","Epoch 81/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3044 - mse: 0.2868 - val_loss: 0.3213 - val_mse: 0.3041\n","Epoch 82/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3039 - mse: 0.2863 - val_loss: 0.3167 - val_mse: 0.2993\n","Epoch 83/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3033 - mse: 0.2858 - val_loss: 0.3207 - val_mse: 0.3032\n","Epoch 84/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3039 - mse: 0.2861 - val_loss: 0.3178 - val_mse: 0.3002\n","Epoch 85/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3035 - mse: 0.2857 - val_loss: 0.3174 - val_mse: 0.2998\n","Epoch 86/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3032 - mse: 0.2854 - val_loss: 0.3180 - val_mse: 0.3003\n","Epoch 87/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3033 - mse: 0.2855 - val_loss: 0.3180 - val_mse: 0.3004\n","Epoch 88/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3028 - mse: 0.2852 - val_loss: 0.3178 - val_mse: 0.3001\n","Epoch 89/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3027 - mse: 0.2850 - val_loss: 0.3189 - val_mse: 0.3013\n","Epoch 90/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3024 - mse: 0.2846 - val_loss: 0.3163 - val_mse: 0.2985\n","Epoch 91/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3024 - mse: 0.2845 - val_loss: 0.3192 - val_mse: 0.3013\n","Epoch 92/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3023 - mse: 0.2845 - val_loss: 0.3183 - val_mse: 0.3005\n","Epoch 93/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3018 - mse: 0.2840 - val_loss: 0.3163 - val_mse: 0.2984\n","Epoch 94/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3017 - mse: 0.2838 - val_loss: 0.3177 - val_mse: 0.2998\n","Epoch 95/200\n","406/406 [==============================] - 34s 83ms/step - loss: 0.3019 - mse: 0.2837 - val_loss: 0.3194 - val_mse: 0.3013\n","Epoch 96/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3015 - mse: 0.2833 - val_loss: 0.3174 - val_mse: 0.2994\n","Epoch 97/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3013 - mse: 0.2831 - val_loss: 0.3181 - val_mse: 0.3000\n","Epoch 98/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3012 - mse: 0.2829 - val_loss: 0.3205 - val_mse: 0.3025\n","Epoch 99/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3011 - mse: 0.2830 - val_loss: 0.3185 - val_mse: 0.3004\n","Epoch 100/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3011 - mse: 0.2829 - val_loss: 0.3189 - val_mse: 0.3008\n","Epoch 101/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3010 - mse: 0.2827 - val_loss: 0.3186 - val_mse: 0.3004\n","Epoch 102/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3008 - mse: 0.2825 - val_loss: 0.3158 - val_mse: 0.2977\n","Epoch 103/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3009 - mse: 0.2825 - val_loss: 0.3195 - val_mse: 0.3013\n","Epoch 104/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3005 - mse: 0.2821 - val_loss: 0.3180 - val_mse: 0.2998\n","Epoch 105/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3003 - mse: 0.2820 - val_loss: 0.3183 - val_mse: 0.2999\n","Epoch 106/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3004 - mse: 0.2818 - val_loss: 0.3169 - val_mse: 0.2985\n","Epoch 107/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3003 - mse: 0.2817 - val_loss: 0.3168 - val_mse: 0.2985\n","Epoch 108/200\n","406/406 [==============================] - 33s 83ms/step - loss: 0.3000 - mse: 0.2814 - val_loss: 0.3177 - val_mse: 0.2993\n","Epoch 109/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3004 - mse: 0.2816 - val_loss: 0.3176 - val_mse: 0.2989\n","Epoch 110/200\n","406/406 [==============================] - 34s 83ms/step - loss: 0.3003 - mse: 0.2816 - val_loss: 0.3197 - val_mse: 0.3012\n","Epoch 111/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2997 - mse: 0.2810 - val_loss: 0.3185 - val_mse: 0.3000\n","Epoch 112/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2996 - mse: 0.2809 - val_loss: 0.3185 - val_mse: 0.2999\n","Epoch 113/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2997 - mse: 0.2808 - val_loss: 0.3185 - val_mse: 0.2999\n","Epoch 114/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2995 - mse: 0.2808 - val_loss: 0.3204 - val_mse: 0.3019\n","Epoch 115/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2992 - mse: 0.2805 - val_loss: 0.3188 - val_mse: 0.3002\n","Epoch 116/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2993 - mse: 0.2804 - val_loss: 0.3180 - val_mse: 0.2992\n","Epoch 117/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2992 - mse: 0.2803 - val_loss: 0.3197 - val_mse: 0.3008\n","Epoch 118/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2992 - mse: 0.2803 - val_loss: 0.3196 - val_mse: 0.3010\n","Epoch 119/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2991 - mse: 0.2802 - val_loss: 0.3218 - val_mse: 0.3030\n","Epoch 120/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2988 - mse: 0.2798 - val_loss: 0.3182 - val_mse: 0.2993\n","Epoch 121/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2987 - mse: 0.2797 - val_loss: 0.3192 - val_mse: 0.3003\n","Epoch 122/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2990 - mse: 0.2800 - val_loss: 0.3201 - val_mse: 0.3010\n","Epoch 123/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2985 - mse: 0.2793 - val_loss: 0.3268 - val_mse: 0.3076\n","Epoch 124/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2989 - mse: 0.2796 - val_loss: 0.3205 - val_mse: 0.3015\n","Epoch 125/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2989 - mse: 0.2797 - val_loss: 0.3188 - val_mse: 0.2999\n","Epoch 126/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2981 - mse: 0.2789 - val_loss: 0.3190 - val_mse: 0.2999\n","Epoch 127/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2979 - mse: 0.2787 - val_loss: 0.3359 - val_mse: 0.3168\n","Epoch 128/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2981 - mse: 0.2789 - val_loss: 0.3226 - val_mse: 0.3034\n","Epoch 129/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2980 - mse: 0.2787 - val_loss: 0.3184 - val_mse: 0.2993\n","Epoch 130/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2980 - mse: 0.2788 - val_loss: 0.3191 - val_mse: 0.2999\n","Epoch 131/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2978 - mse: 0.2784 - val_loss: 0.3186 - val_mse: 0.2994\n","Epoch 132/200\n","406/406 [==============================] - 33s 82ms/step - loss: 0.2977 - mse: 0.2784 - val_loss: 0.3180 - val_mse: 0.2987\n","Epoch 133/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2974 - mse: 0.2781 - val_loss: 0.3230 - val_mse: 0.3037\n","Epoch 134/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2972 - mse: 0.2777 - val_loss: 0.3188 - val_mse: 0.2995\n","Epoch 135/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2971 - mse: 0.2776 - val_loss: 0.3188 - val_mse: 0.2994\n","Epoch 136/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2976 - mse: 0.2780 - val_loss: 0.3195 - val_mse: 0.3000\n","Epoch 137/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2975 - mse: 0.2779 - val_loss: 0.3223 - val_mse: 0.3028\n","Epoch 138/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2972 - mse: 0.2775 - val_loss: 0.3206 - val_mse: 0.3012\n","Epoch 139/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2971 - mse: 0.2776 - val_loss: 0.3214 - val_mse: 0.3019\n","Epoch 140/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2969 - mse: 0.2772 - val_loss: 0.3209 - val_mse: 0.3014\n","Epoch 141/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2969 - mse: 0.2771 - val_loss: 0.3202 - val_mse: 0.3006\n","Epoch 142/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2969 - mse: 0.2773 - val_loss: 0.3201 - val_mse: 0.3004\n","Epoch 143/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2969 - mse: 0.2771 - val_loss: 0.3212 - val_mse: 0.3016\n","Epoch 144/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2963 - mse: 0.2766 - val_loss: 0.3198 - val_mse: 0.3001\n","Epoch 145/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2963 - mse: 0.2766 - val_loss: 0.3214 - val_mse: 0.3015\n","Epoch 146/200\n","406/406 [==============================] - 33s 81ms/step - loss: 0.2961 - mse: 0.2762 - val_loss: 0.3228 - val_mse: 0.3029\n","Epoch 147/200\n","402/406 [============================>.] - ETA: 0s - loss: 0.2963 - mse: 0.2765Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5_ObgqsmSWxY","colab_type":"code","colab":{}},"source":["train_result=cnn_model.predict([train_x[train,:132],train_x[train,132:]])\n","val_result=cnn_model.predict([train_x[val,:132],train_x[val,132:]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ai483DUVS7uP","colab_type":"code","colab":{}},"source":["train_mse=mse(train_result,train_true_y[train])\n","train_rmsle=rmsle(train_result,train_true_y[train])\n","val_mse=mse(val_result,train_true_y[val])\n","val_rmsle=rmsle(val_result,train_true_y[val])\n","train_mse_list.append(train_mse)\n","val_mse_list.append(val_mse)\n","train_rmsle_list.append(train_rmsle)\n","val_rmsle_list.append(val_rmsle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sgBuBoTb1m8","colab_type":"code","outputId":"62429266-8608-4064-ffbd-d0106afb74a2","executionInfo":{"status":"ok","timestamp":1586623476788,"user_tz":300,"elapsed":401,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_rmsle"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5463470840583688"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"aRr6MYjXcHQn","colab_type":"code","outputId":"201e0c47-2513-4239-d2a4-34535032e8d3","executionInfo":{"status":"ok","timestamp":1586626788349,"user_tz":300,"elapsed":1318847,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train,val=index_list[1]\n","cnn_model=CNN(132,56,[8,32,64],[4,8,16])\n","cnn_model.compile(loss='mse', \n","                optimizer='adam',\n","                metrics=['mse'])\n","cnn_model.fit([train_x[train,:132],train_x[train,132:]],train_y[train],batch_size=2048,epochs=100,validation_data=([train_x[val,:132],train_x[val,132:]],train_y[val]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 3584)\n","Epoch 1/100\n","406/406 [==============================] - 33s 82ms/step - loss: 1.8705 - mse: 1.4196 - val_loss: 0.8365 - val_mse: 0.4286\n","Epoch 2/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.7620 - mse: 0.3914 - val_loss: 0.7204 - val_mse: 0.3832\n","Epoch 3/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.6861 - mse: 0.3765 - val_loss: 0.6511 - val_mse: 0.3663\n","Epoch 4/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.6289 - mse: 0.3652 - val_loss: 0.5952 - val_mse: 0.3509\n","Epoch 5/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5857 - mse: 0.3583 - val_loss: 0.5656 - val_mse: 0.3537\n","Epoch 6/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5498 - mse: 0.3517 - val_loss: 0.5366 - val_mse: 0.3514\n","Epoch 7/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5211 - mse: 0.3475 - val_loss: 0.5251 - val_mse: 0.3624\n","Epoch 8/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4957 - mse: 0.3430 - val_loss: 0.4792 - val_mse: 0.3360\n","Epoch 9/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4749 - mse: 0.3403 - val_loss: 0.4576 - val_mse: 0.3313\n","Epoch 10/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4548 - mse: 0.3362 - val_loss: 0.4409 - val_mse: 0.3296\n","Epoch 11/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4382 - mse: 0.3335 - val_loss: 0.4477 - val_mse: 0.3496\n","Epoch 12/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4245 - mse: 0.3323 - val_loss: 0.4196 - val_mse: 0.3334\n","Epoch 13/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4106 - mse: 0.3297 - val_loss: 0.4132 - val_mse: 0.3373\n","Epoch 14/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3993 - mse: 0.3282 - val_loss: 0.3967 - val_mse: 0.3301\n","Epoch 15/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3897 - mse: 0.3270 - val_loss: 0.3809 - val_mse: 0.3223\n","Epoch 16/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3808 - mse: 0.3258 - val_loss: 0.3771 - val_mse: 0.3253\n","Epoch 17/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3713 - mse: 0.3229 - val_loss: 0.3679 - val_mse: 0.3224\n","Epoch 18/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3657 - mse: 0.3228 - val_loss: 0.3585 - val_mse: 0.3182\n","Epoch 19/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3595 - mse: 0.3215 - val_loss: 0.3662 - val_mse: 0.3304\n","Epoch 20/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3540 - mse: 0.3199 - val_loss: 0.3502 - val_mse: 0.3180\n","Epoch 21/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3500 - mse: 0.3195 - val_loss: 0.3504 - val_mse: 0.3216\n","Epoch 22/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3458 - mse: 0.3182 - val_loss: 0.3424 - val_mse: 0.3159\n","Epoch 23/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3424 - mse: 0.3171 - val_loss: 0.3396 - val_mse: 0.3155\n","Epoch 24/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3397 - mse: 0.3164 - val_loss: 0.3467 - val_mse: 0.3243\n","Epoch 25/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3379 - mse: 0.3160 - val_loss: 0.3510 - val_mse: 0.3296\n","Epoch 26/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3353 - mse: 0.3146 - val_loss: 0.3367 - val_mse: 0.3169\n","Epoch 27/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3335 - mse: 0.3140 - val_loss: 0.3365 - val_mse: 0.3173\n","Epoch 28/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3318 - mse: 0.3132 - val_loss: 0.3329 - val_mse: 0.3146\n","Epoch 29/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3306 - mse: 0.3123 - val_loss: 0.3357 - val_mse: 0.3180\n","Epoch 30/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3296 - mse: 0.3121 - val_loss: 0.3295 - val_mse: 0.3122\n","Epoch 31/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3278 - mse: 0.3109 - val_loss: 0.3328 - val_mse: 0.3162\n","Epoch 32/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3275 - mse: 0.3110 - val_loss: 0.3277 - val_mse: 0.3114\n","Epoch 33/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3262 - mse: 0.3098 - val_loss: 0.3322 - val_mse: 0.3160\n","Epoch 34/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3255 - mse: 0.3091 - val_loss: 0.3258 - val_mse: 0.3096\n","Epoch 35/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3244 - mse: 0.3084 - val_loss: 0.3394 - val_mse: 0.3235\n","Epoch 36/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3228 - mse: 0.3069 - val_loss: 0.3252 - val_mse: 0.3093\n","Epoch 37/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3221 - mse: 0.3062 - val_loss: 0.3278 - val_mse: 0.3120\n","Epoch 38/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3215 - mse: 0.3056 - val_loss: 0.3242 - val_mse: 0.3084\n","Epoch 39/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3194 - mse: 0.3036 - val_loss: 0.3196 - val_mse: 0.3038\n","Epoch 40/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3184 - mse: 0.3026 - val_loss: 0.3227 - val_mse: 0.3069\n","Epoch 41/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3176 - mse: 0.3019 - val_loss: 0.3242 - val_mse: 0.3085\n","Epoch 42/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3178 - mse: 0.3016 - val_loss: 0.3196 - val_mse: 0.3038\n","Epoch 43/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3173 - mse: 0.3012 - val_loss: 0.3200 - val_mse: 0.3042\n","Epoch 44/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3156 - mse: 0.2998 - val_loss: 0.3221 - val_mse: 0.3063\n","Epoch 45/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3155 - mse: 0.2997 - val_loss: 0.3280 - val_mse: 0.3121\n","Epoch 46/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3152 - mse: 0.2993 - val_loss: 0.3223 - val_mse: 0.3064\n","Epoch 47/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3152 - mse: 0.2993 - val_loss: 0.3209 - val_mse: 0.3049\n","Epoch 48/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3143 - mse: 0.2983 - val_loss: 0.3201 - val_mse: 0.3040\n","Epoch 49/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3140 - mse: 0.2981 - val_loss: 0.3209 - val_mse: 0.3050\n","Epoch 50/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3136 - mse: 0.2977 - val_loss: 0.3190 - val_mse: 0.3030\n","Epoch 51/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3130 - mse: 0.2972 - val_loss: 0.3235 - val_mse: 0.3076\n","Epoch 52/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3135 - mse: 0.2974 - val_loss: 0.3260 - val_mse: 0.3098\n","Epoch 53/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3126 - mse: 0.2965 - val_loss: 0.3207 - val_mse: 0.3047\n","Epoch 54/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3117 - mse: 0.2956 - val_loss: 0.3186 - val_mse: 0.3025\n","Epoch 55/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3117 - mse: 0.2954 - val_loss: 0.3177 - val_mse: 0.3015\n","Epoch 56/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3114 - mse: 0.2951 - val_loss: 0.3234 - val_mse: 0.3071\n","Epoch 57/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3112 - mse: 0.2950 - val_loss: 0.3216 - val_mse: 0.3055\n","Epoch 58/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3105 - mse: 0.2942 - val_loss: 0.3174 - val_mse: 0.3010\n","Epoch 59/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3106 - mse: 0.2942 - val_loss: 0.3176 - val_mse: 0.3012\n","Epoch 60/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3104 - mse: 0.2938 - val_loss: 0.3180 - val_mse: 0.3016\n","Epoch 61/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3098 - mse: 0.2934 - val_loss: 0.3204 - val_mse: 0.3039\n","Epoch 62/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3095 - mse: 0.2930 - val_loss: 0.3194 - val_mse: 0.3029\n","Epoch 63/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3090 - mse: 0.2925 - val_loss: 0.3308 - val_mse: 0.3143\n","Epoch 64/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3090 - mse: 0.2924 - val_loss: 0.3187 - val_mse: 0.3020\n","Epoch 65/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3083 - mse: 0.2916 - val_loss: 0.3181 - val_mse: 0.3014\n","Epoch 66/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3084 - mse: 0.2918 - val_loss: 0.3164 - val_mse: 0.2998\n","Epoch 67/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3082 - mse: 0.2916 - val_loss: 0.3170 - val_mse: 0.3003\n","Epoch 68/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3080 - mse: 0.2913 - val_loss: 0.3169 - val_mse: 0.3003\n","Epoch 69/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3076 - mse: 0.2910 - val_loss: 0.3199 - val_mse: 0.3032\n","Epoch 70/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3076 - mse: 0.2908 - val_loss: 0.3194 - val_mse: 0.3026\n","Epoch 71/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3071 - mse: 0.2903 - val_loss: 0.3213 - val_mse: 0.3046\n","Epoch 72/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3069 - mse: 0.2899 - val_loss: 0.3187 - val_mse: 0.3018\n","Epoch 73/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3069 - mse: 0.2900 - val_loss: 0.3193 - val_mse: 0.3023\n","Epoch 74/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3070 - mse: 0.2900 - val_loss: 0.3182 - val_mse: 0.3013\n","Epoch 75/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3063 - mse: 0.2893 - val_loss: 0.3179 - val_mse: 0.3009\n","Epoch 76/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3061 - mse: 0.2891 - val_loss: 0.3138 - val_mse: 0.2968\n","Epoch 77/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3060 - mse: 0.2888 - val_loss: 0.3174 - val_mse: 0.3005\n","Epoch 78/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3056 - mse: 0.2886 - val_loss: 0.3184 - val_mse: 0.3014\n","Epoch 79/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3056 - mse: 0.2886 - val_loss: 0.3185 - val_mse: 0.3013\n","Epoch 80/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3054 - mse: 0.2883 - val_loss: 0.3199 - val_mse: 0.3027\n","Epoch 81/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3053 - mse: 0.2881 - val_loss: 0.3171 - val_mse: 0.3000\n","Epoch 82/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3050 - mse: 0.2878 - val_loss: 0.3186 - val_mse: 0.3013\n","Epoch 83/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3045 - mse: 0.2873 - val_loss: 0.3204 - val_mse: 0.3031\n","Epoch 84/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3047 - mse: 0.2874 - val_loss: 0.3170 - val_mse: 0.2997\n","Epoch 85/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3047 - mse: 0.2874 - val_loss: 0.3169 - val_mse: 0.2997\n","Epoch 86/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3043 - mse: 0.2870 - val_loss: 0.3191 - val_mse: 0.3018\n","Epoch 87/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3041 - mse: 0.2866 - val_loss: 0.3185 - val_mse: 0.3011\n","Epoch 88/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3040 - mse: 0.2866 - val_loss: 0.3170 - val_mse: 0.2995\n","Epoch 89/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3038 - mse: 0.2864 - val_loss: 0.3179 - val_mse: 0.3004\n","Epoch 90/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3031 - mse: 0.2856 - val_loss: 0.3196 - val_mse: 0.3021\n","Epoch 91/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3033 - mse: 0.2858 - val_loss: 0.3168 - val_mse: 0.2993\n","Epoch 92/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3035 - mse: 0.2859 - val_loss: 0.3180 - val_mse: 0.3004\n","Epoch 93/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3032 - mse: 0.2855 - val_loss: 0.3185 - val_mse: 0.3009\n","Epoch 94/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3028 - mse: 0.2852 - val_loss: 0.3171 - val_mse: 0.2995\n","Epoch 95/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3028 - mse: 0.2851 - val_loss: 0.3174 - val_mse: 0.2997\n","Epoch 96/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3028 - mse: 0.2851 - val_loss: 0.3185 - val_mse: 0.3009\n","Epoch 97/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3025 - mse: 0.2847 - val_loss: 0.3163 - val_mse: 0.2986\n","Epoch 98/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3025 - mse: 0.2847 - val_loss: 0.3180 - val_mse: 0.3002\n","Epoch 99/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3024 - mse: 0.2844 - val_loss: 0.3179 - val_mse: 0.3000\n","Epoch 100/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3025 - mse: 0.2845 - val_loss: 0.3181 - val_mse: 0.3001\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3f52d27c18>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"2ICff9SIcNw1","colab_type":"code","colab":{}},"source":["train_result=cnn_model.predict([train_x[train,:132],train_x[train,132:]])\n","val_result=cnn_model.predict([train_x[val,:132],train_x[val,132:]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfiVGqLlcSWO","colab_type":"code","colab":{}},"source":["train_mse=mse(train_result,train_true_y[train])\n","train_rmsle=rmsle(train_result,train_true_y[train])\n","val_mse=mse(val_result,train_true_y[val])\n","val_rmsle=rmsle(val_result,train_true_y[val])\n","train_mse_list.append(train_mse)\n","val_mse_list.append(val_mse)\n","train_rmsle_list.append(train_rmsle)\n","val_rmsle_list.append(val_rmsle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkdWonCpcVfi","colab_type":"code","outputId":"a3334139-c1f8-4002-c5cf-05a2507a2aa5","executionInfo":{"status":"ok","timestamp":1586629994124,"user_tz":300,"elapsed":548,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_rmsle"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[962.1196778333715, 1023.1848829278421]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"PcpaX-IXfkH5","colab_type":"code","outputId":"8ff5b9e8-4470-4148-843d-c876d6622485","executionInfo":{"status":"ok","timestamp":1586633252473,"user_tz":300,"elapsed":2544073,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train,val=index_list[2]\n","cnn_model=CNN(132,56,[8,32,64],[4,8,16])\n","cnn_model.compile(loss='mse', \n","                optimizer='adam',\n","                metrics=['mse'])\n","cnn_model.fit([train_x[train,:132],train_x[train,132:]],train_y[train],batch_size=2048,epochs=100,validation_data=([train_x[val,:132],train_x[val,132:]],train_y[val]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 3584)\n","Epoch 1/100\n","406/406 [==============================] - 34s 83ms/step - loss: 1.3334 - mse: 0.8857 - val_loss: 0.8383 - val_mse: 0.4377\n","Epoch 2/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.7451 - mse: 0.3855 - val_loss: 0.7163 - val_mse: 0.3933\n","Epoch 3/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.6620 - mse: 0.3699 - val_loss: 0.6214 - val_mse: 0.3572\n","Epoch 4/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.6033 - mse: 0.3627 - val_loss: 0.5637 - val_mse: 0.3446\n","Epoch 5/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.5558 - mse: 0.3553 - val_loss: 0.5251 - val_mse: 0.3414\n","Epoch 6/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.5183 - mse: 0.3495 - val_loss: 0.4913 - val_mse: 0.3360\n","Epoch 7/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.4879 - mse: 0.3448 - val_loss: 0.4722 - val_mse: 0.3402\n","Epoch 8/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4639 - mse: 0.3419 - val_loss: 0.4460 - val_mse: 0.3329\n","Epoch 9/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4438 - mse: 0.3391 - val_loss: 0.4254 - val_mse: 0.3282\n","Epoch 10/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4249 - mse: 0.3348 - val_loss: 0.4417 - val_mse: 0.3579\n","Epoch 11/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4113 - mse: 0.3333 - val_loss: 0.4037 - val_mse: 0.3310\n","Epoch 12/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3985 - mse: 0.3310 - val_loss: 0.3868 - val_mse: 0.3240\n","Epoch 13/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3867 - mse: 0.3279 - val_loss: 0.3853 - val_mse: 0.3305\n","Epoch 14/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3762 - mse: 0.3249 - val_loss: 0.3724 - val_mse: 0.3245\n","Epoch 15/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3665 - mse: 0.3216 - val_loss: 0.3590 - val_mse: 0.3167\n","Epoch 16/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3588 - mse: 0.3191 - val_loss: 0.3495 - val_mse: 0.3122\n","Epoch 17/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3531 - mse: 0.3179 - val_loss: 0.3454 - val_mse: 0.3120\n","Epoch 18/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3473 - mse: 0.3159 - val_loss: 0.3602 - val_mse: 0.3303\n","Epoch 19/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3432 - mse: 0.3149 - val_loss: 0.3384 - val_mse: 0.3115\n","Epoch 20/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3394 - mse: 0.3135 - val_loss: 0.3404 - val_mse: 0.3157\n","Epoch 21/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3360 - mse: 0.3122 - val_loss: 0.3366 - val_mse: 0.3138\n","Epoch 22/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3327 - mse: 0.3106 - val_loss: 0.3416 - val_mse: 0.3203\n","Epoch 23/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3304 - mse: 0.3099 - val_loss: 0.3289 - val_mse: 0.3090\n","Epoch 24/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3288 - mse: 0.3094 - val_loss: 0.3286 - val_mse: 0.3094\n","Epoch 25/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3261 - mse: 0.3076 - val_loss: 0.3255 - val_mse: 0.3073\n","Epoch 26/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3254 - mse: 0.3078 - val_loss: 0.3243 - val_mse: 0.3070\n","Epoch 27/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3233 - mse: 0.3064 - val_loss: 0.3295 - val_mse: 0.3127\n","Epoch 28/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3218 - mse: 0.3054 - val_loss: 0.3223 - val_mse: 0.3061\n","Epoch 29/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3213 - mse: 0.3053 - val_loss: 0.3319 - val_mse: 0.3161\n","Epoch 30/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3198 - mse: 0.3042 - val_loss: 0.3223 - val_mse: 0.3066\n","Epoch 31/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3190 - mse: 0.3038 - val_loss: 0.3210 - val_mse: 0.3055\n","Epoch 32/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3185 - mse: 0.3031 - val_loss: 0.3254 - val_mse: 0.3103\n","Epoch 33/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3177 - mse: 0.3027 - val_loss: 0.3223 - val_mse: 0.3073\n","Epoch 34/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3166 - mse: 0.3017 - val_loss: 0.3190 - val_mse: 0.3039\n","Epoch 35/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3177 - mse: 0.3030 - val_loss: 0.3213 - val_mse: 0.3064\n","Epoch 36/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3158 - mse: 0.3012 - val_loss: 0.3289 - val_mse: 0.3142\n","Epoch 37/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3149 - mse: 0.3004 - val_loss: 0.3200 - val_mse: 0.3055\n","Epoch 38/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3145 - mse: 0.2999 - val_loss: 0.3166 - val_mse: 0.3020\n","Epoch 39/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3137 - mse: 0.2993 - val_loss: 0.3347 - val_mse: 0.3201\n","Epoch 40/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3142 - mse: 0.2997 - val_loss: 0.3189 - val_mse: 0.3042\n","Epoch 41/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3130 - mse: 0.2984 - val_loss: 0.3178 - val_mse: 0.3033\n","Epoch 42/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3130 - mse: 0.2985 - val_loss: 0.3235 - val_mse: 0.3088\n","Epoch 43/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3123 - mse: 0.2976 - val_loss: 0.3163 - val_mse: 0.3017\n","Epoch 44/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3118 - mse: 0.2972 - val_loss: 0.3202 - val_mse: 0.3054\n","Epoch 45/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3119 - mse: 0.2972 - val_loss: 0.3176 - val_mse: 0.3029\n","Epoch 46/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3109 - mse: 0.2963 - val_loss: 0.3211 - val_mse: 0.3064\n","Epoch 47/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3108 - mse: 0.2961 - val_loss: 0.3211 - val_mse: 0.3064\n","Epoch 48/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3105 - mse: 0.2961 - val_loss: 0.3168 - val_mse: 0.3023\n","Epoch 49/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3099 - mse: 0.2953 - val_loss: 0.3184 - val_mse: 0.3039\n","Epoch 50/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3098 - mse: 0.2953 - val_loss: 0.3168 - val_mse: 0.3021\n","Epoch 51/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3091 - mse: 0.2946 - val_loss: 0.3254 - val_mse: 0.3108\n","Epoch 52/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3086 - mse: 0.2942 - val_loss: 0.3186 - val_mse: 0.3040\n","Epoch 53/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3090 - mse: 0.2944 - val_loss: 0.3175 - val_mse: 0.3029\n","Epoch 54/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3090 - mse: 0.2944 - val_loss: 0.3172 - val_mse: 0.3024\n","Epoch 55/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3080 - mse: 0.2933 - val_loss: 0.3218 - val_mse: 0.3070\n","Epoch 56/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3080 - mse: 0.2932 - val_loss: 0.3163 - val_mse: 0.3015\n","Epoch 57/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3084 - mse: 0.2936 - val_loss: 0.3155 - val_mse: 0.3006\n","Epoch 58/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3075 - mse: 0.2926 - val_loss: 0.3168 - val_mse: 0.3019\n","Epoch 59/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3070 - mse: 0.2922 - val_loss: 0.3285 - val_mse: 0.3136\n","Epoch 60/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3066 - mse: 0.2918 - val_loss: 0.3164 - val_mse: 0.3014\n","Epoch 61/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3069 - mse: 0.2919 - val_loss: 0.3190 - val_mse: 0.3040\n","Epoch 62/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3067 - mse: 0.2918 - val_loss: 0.3150 - val_mse: 0.2999\n","Epoch 63/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3058 - mse: 0.2909 - val_loss: 0.3152 - val_mse: 0.3003\n","Epoch 64/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3055 - mse: 0.2905 - val_loss: 0.3143 - val_mse: 0.2992\n","Epoch 65/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3056 - mse: 0.2905 - val_loss: 0.3166 - val_mse: 0.3014\n","Epoch 66/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3055 - mse: 0.2902 - val_loss: 0.3154 - val_mse: 0.3001\n","Epoch 67/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3051 - mse: 0.2898 - val_loss: 0.3150 - val_mse: 0.2997\n","Epoch 68/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3047 - mse: 0.2895 - val_loss: 0.3183 - val_mse: 0.3030\n","Epoch 69/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3051 - mse: 0.2898 - val_loss: 0.3146 - val_mse: 0.2993\n","Epoch 70/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3044 - mse: 0.2891 - val_loss: 0.3176 - val_mse: 0.3022\n","Epoch 71/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3041 - mse: 0.2887 - val_loss: 0.3165 - val_mse: 0.3011\n","Epoch 72/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3039 - mse: 0.2885 - val_loss: 0.3173 - val_mse: 0.3018\n","Epoch 73/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3035 - mse: 0.2881 - val_loss: 0.3145 - val_mse: 0.2990\n","Epoch 74/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3034 - mse: 0.2878 - val_loss: 0.3165 - val_mse: 0.3009\n","Epoch 75/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3038 - mse: 0.2882 - val_loss: 0.3151 - val_mse: 0.2994\n","Epoch 76/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3033 - mse: 0.2875 - val_loss: 0.3151 - val_mse: 0.2994\n","Epoch 77/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3028 - mse: 0.2870 - val_loss: 0.3195 - val_mse: 0.3038\n","Epoch 78/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3031 - mse: 0.2873 - val_loss: 0.3197 - val_mse: 0.3040\n","Epoch 79/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3022 - mse: 0.2865 - val_loss: 0.3161 - val_mse: 0.3005\n","Epoch 80/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3020 - mse: 0.2863 - val_loss: 0.3144 - val_mse: 0.2987\n","Epoch 81/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3019 - mse: 0.2862 - val_loss: 0.3159 - val_mse: 0.3002\n","Epoch 82/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3022 - mse: 0.2864 - val_loss: 0.3210 - val_mse: 0.3052\n","Epoch 83/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3018 - mse: 0.2860 - val_loss: 0.3184 - val_mse: 0.3026\n","Epoch 84/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3020 - mse: 0.2861 - val_loss: 0.3171 - val_mse: 0.3011\n","Epoch 85/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3014 - mse: 0.2853 - val_loss: 0.3147 - val_mse: 0.2988\n","Epoch 86/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3016 - mse: 0.2856 - val_loss: 0.3151 - val_mse: 0.2992\n","Epoch 87/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3008 - mse: 0.2849 - val_loss: 0.3182 - val_mse: 0.3023\n","Epoch 88/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3010 - mse: 0.2850 - val_loss: 0.3150 - val_mse: 0.2989\n","Epoch 89/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3007 - mse: 0.2847 - val_loss: 0.3158 - val_mse: 0.2997\n","Epoch 90/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3006 - mse: 0.2845 - val_loss: 0.3147 - val_mse: 0.2987\n","Epoch 91/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3005 - mse: 0.2845 - val_loss: 0.3164 - val_mse: 0.3002\n","Epoch 92/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3007 - mse: 0.2845 - val_loss: 0.3165 - val_mse: 0.3003\n","Epoch 93/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3000 - mse: 0.2839 - val_loss: 0.3158 - val_mse: 0.2996\n","Epoch 94/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.3003 - mse: 0.2840 - val_loss: 0.3160 - val_mse: 0.2997\n","Epoch 95/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.2999 - mse: 0.2837 - val_loss: 0.3165 - val_mse: 0.3002\n","Epoch 96/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.2998 - mse: 0.2836 - val_loss: 0.3343 - val_mse: 0.3179\n","Epoch 97/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.2998 - mse: 0.2835 - val_loss: 0.3160 - val_mse: 0.2996\n","Epoch 98/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.2997 - mse: 0.2831 - val_loss: 0.3172 - val_mse: 0.3008\n","Epoch 99/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.2994 - mse: 0.2830 - val_loss: 0.3159 - val_mse: 0.2995\n","Epoch 100/100\n","406/406 [==============================] - 32s 79ms/step - loss: 0.2990 - mse: 0.2826 - val_loss: 0.3178 - val_mse: 0.3013\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3d0d1f74a8>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"zYMLaZIsfmaZ","colab_type":"code","colab":{}},"source":["train_result=cnn_model.predict([train_x[train,:132],train_x[train,132:]])\n","val_result=cnn_model.predict([train_x[val,:132],train_x[val,132:]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QElmTC7AfpDD","colab_type":"code","colab":{}},"source":["train_mse=mse(train_result,train_true_y[train])\n","train_rmsle=rmsle(train_result,train_true_y[train])\n","val_mse=mse(val_result,train_true_y[val])\n","val_rmsle=rmsle(val_result,train_true_y[val])\n","train_mse_list.append(train_mse)\n","val_mse_list.append(val_mse)\n","train_rmsle_list.append(train_rmsle)\n","val_rmsle_list.append(val_rmsle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmwTRDQ7friw","colab_type":"code","outputId":"ab2dcf66-45a3-4ff3-f9a0-c893a8d69ba8","executionInfo":{"status":"ok","timestamp":1586633531610,"user_tz":300,"elapsed":370,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_rmsle"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.548929705520856"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"TmzDCByXmJry","colab_type":"code","outputId":"01d183fd-01f9-4d21-fde8-391d6d9d3768","executionInfo":{"status":"ok","timestamp":1586633533147,"user_tz":300,"elapsed":364,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(train_rmsle_list)\n","print(val_rmsle_list)\n","print(train_mse_list)\n","print(val_mse_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.5208154900823853, 0.5256938382109262, 0.525401342055649]\n","[0.5463470840583688, 0.5478289952287667, 0.548929705520856]\n","[962.1196778333715, 1023.1848829278421, 999.4979940776974]\n","[1051.1171796139038, 1129.3330861106715, 1069.9572244904255]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"On0o3BpOg-0Z","colab_type":"code","outputId":"5a1f67f6-efc7-497b-84fc-67b1bb039e14","executionInfo":{"status":"ok","timestamp":1586649057347,"user_tz":300,"elapsed":3294143,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train,val=index_list[3]\n","cnn_model=CNN(132,56,[8,32,64],[4,8,16])\n","cnn_model.compile(loss='mse', \n","                optimizer='adam',\n","                metrics=['mse'])\n","cnn_model.fit([train_x[train,:132],train_x[train,132:]],train_y[train],batch_size=2048,epochs=100,validation_data=([train_x[val,:132],train_x[val,132:]],train_y[val]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 3584)\n","Epoch 1/100\n","406/406 [==============================] - 34s 84ms/step - loss: 1.7427 - mse: 1.2823 - val_loss: 0.8418 - val_mse: 0.4167\n","Epoch 2/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.7812 - mse: 0.3893 - val_loss: 0.7268 - val_mse: 0.3662\n","Epoch 3/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.7071 - mse: 0.3733 - val_loss: 0.6600 - val_mse: 0.3519\n","Epoch 4/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.6528 - mse: 0.3665 - val_loss: 0.6100 - val_mse: 0.3451\n","Epoch 5/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.6042 - mse: 0.3574 - val_loss: 0.5698 - val_mse: 0.3407\n","Epoch 6/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5649 - mse: 0.3510 - val_loss: 0.5350 - val_mse: 0.3361\n","Epoch 7/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5324 - mse: 0.3463 - val_loss: 0.5092 - val_mse: 0.3361\n","Epoch 8/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.5045 - mse: 0.3426 - val_loss: 0.4802 - val_mse: 0.3293\n","Epoch 9/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4795 - mse: 0.3381 - val_loss: 0.4621 - val_mse: 0.3304\n","Epoch 10/100\n","406/406 [==============================] - 33s 82ms/step - loss: 0.4568 - mse: 0.3331 - val_loss: 0.4470 - val_mse: 0.3319\n","Epoch 11/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4387 - mse: 0.3306 - val_loss: 0.4209 - val_mse: 0.3203\n","Epoch 12/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4218 - mse: 0.3274 - val_loss: 0.4047 - val_mse: 0.3171\n","Epoch 13/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.4075 - mse: 0.3253 - val_loss: 0.3908 - val_mse: 0.3144\n","Epoch 14/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3950 - mse: 0.3232 - val_loss: 0.3925 - val_mse: 0.3260\n","Epoch 15/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3839 - mse: 0.3214 - val_loss: 0.3783 - val_mse: 0.3203\n","Epoch 16/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3740 - mse: 0.3194 - val_loss: 0.3617 - val_mse: 0.3110\n","Epoch 17/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3660 - mse: 0.3182 - val_loss: 0.3602 - val_mse: 0.3156\n","Epoch 18/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3596 - mse: 0.3173 - val_loss: 0.3492 - val_mse: 0.3098\n","Epoch 19/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3521 - mse: 0.3147 - val_loss: 0.3447 - val_mse: 0.3098\n","Epoch 20/100\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3478 - mse: 0.3144 - val_loss: 0.3417 - val_mse: 0.3105\n","Epoch 21/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3433 - mse: 0.3134 - val_loss: 0.3454 - val_mse: 0.3174\n","Epoch 22/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3453 - mse: 0.3179 - val_loss: 0.3765 - val_mse: 0.3508\n","Epoch 23/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3381 - mse: 0.3131 - val_loss: 0.3325 - val_mse: 0.3089\n","Epoch 24/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3337 - mse: 0.3107 - val_loss: 0.3488 - val_mse: 0.3270\n","Epoch 25/100\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3318 - mse: 0.3102 - val_loss: 0.3291 - val_mse: 0.3088\n","Epoch 26/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3294 - mse: 0.3092 - val_loss: 0.3342 - val_mse: 0.3152\n","Epoch 27/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3269 - mse: 0.3080 - val_loss: 0.3258 - val_mse: 0.3076\n","Epoch 28/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3262 - mse: 0.3081 - val_loss: 0.3211 - val_mse: 0.3040\n","Epoch 29/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3240 - mse: 0.3068 - val_loss: 0.3247 - val_mse: 0.3083\n","Epoch 30/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3226 - mse: 0.3057 - val_loss: 0.3715 - val_mse: 0.3555\n","Epoch 31/100\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3219 - mse: 0.3058 - val_loss: 0.3528 - val_mse: 0.3374\n","Epoch 32/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3208 - mse: 0.3049 - val_loss: 0.3245 - val_mse: 0.3094\n","Epoch 33/100\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3203 - mse: 0.3049 - val_loss: 0.3195 - val_mse: 0.3047\n","Epoch 34/100\n","406/406 [==============================] - 33s 82ms/step - loss: 0.3185 - mse: 0.3034 - val_loss: 0.3209 - val_mse: 0.3063\n","Epoch 35/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3181 - mse: 0.3029 - val_loss: 0.3225 - val_mse: 0.3082\n","Epoch 36/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3177 - mse: 0.3030 - val_loss: 0.3160 - val_mse: 0.3019\n","Epoch 37/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3165 - mse: 0.3020 - val_loss: 0.3339 - val_mse: 0.3198\n","Epoch 38/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3160 - mse: 0.3014 - val_loss: 0.3203 - val_mse: 0.3062\n","Epoch 39/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3159 - mse: 0.3013 - val_loss: 0.3694 - val_mse: 0.3552\n","Epoch 40/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3154 - mse: 0.3010 - val_loss: 0.3162 - val_mse: 0.3022\n","Epoch 41/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3144 - mse: 0.3000 - val_loss: 0.3691 - val_mse: 0.3551\n","Epoch 42/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3139 - mse: 0.2996 - val_loss: 0.3203 - val_mse: 0.3064\n","Epoch 43/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3138 - mse: 0.2995 - val_loss: 0.3213 - val_mse: 0.3074\n","Epoch 44/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3134 - mse: 0.2990 - val_loss: 0.3223 - val_mse: 0.3083\n","Epoch 45/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3127 - mse: 0.2984 - val_loss: 0.3588 - val_mse: 0.3449\n","Epoch 46/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3125 - mse: 0.2982 - val_loss: 0.3596 - val_mse: 0.3456\n","Epoch 47/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3122 - mse: 0.2978 - val_loss: 0.3144 - val_mse: 0.3004\n","Epoch 48/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3119 - mse: 0.2975 - val_loss: 0.3154 - val_mse: 0.3013\n","Epoch 49/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3118 - mse: 0.2973 - val_loss: 0.3282 - val_mse: 0.3140\n","Epoch 50/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3112 - mse: 0.2966 - val_loss: 0.3319 - val_mse: 0.3178\n","Epoch 51/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3111 - mse: 0.2966 - val_loss: 0.3151 - val_mse: 0.3011\n","Epoch 52/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3106 - mse: 0.2959 - val_loss: 0.3160 - val_mse: 0.3017\n","Epoch 53/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3100 - mse: 0.2953 - val_loss: 0.3616 - val_mse: 0.3473\n","Epoch 54/100\n","406/406 [==============================] - 33s 81ms/step - loss: 0.3101 - mse: 0.2953 - val_loss: 0.3687 - val_mse: 0.3542\n","Epoch 55/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3097 - mse: 0.2950 - val_loss: 0.3151 - val_mse: 0.3008\n","Epoch 56/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3101 - mse: 0.2952 - val_loss: 0.3596 - val_mse: 0.3451\n","Epoch 57/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3091 - mse: 0.2943 - val_loss: 0.3126 - val_mse: 0.2982\n","Epoch 58/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3090 - mse: 0.2941 - val_loss: 0.3176 - val_mse: 0.3031\n","Epoch 59/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3084 - mse: 0.2935 - val_loss: 0.3171 - val_mse: 0.3026\n","Epoch 60/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3085 - mse: 0.2934 - val_loss: 0.3172 - val_mse: 0.3027\n","Epoch 61/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3081 - mse: 0.2931 - val_loss: 0.3136 - val_mse: 0.2989\n","Epoch 62/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3079 - mse: 0.2928 - val_loss: 0.3136 - val_mse: 0.2989\n","Epoch 63/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3071 - mse: 0.2921 - val_loss: 0.3396 - val_mse: 0.3248\n","Epoch 64/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3075 - mse: 0.2923 - val_loss: 0.3183 - val_mse: 0.3035\n","Epoch 65/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3068 - mse: 0.2917 - val_loss: 0.3149 - val_mse: 0.3000\n","Epoch 66/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3067 - mse: 0.2916 - val_loss: 0.3147 - val_mse: 0.2997\n","Epoch 67/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3070 - mse: 0.2915 - val_loss: 0.3140 - val_mse: 0.2989\n","Epoch 68/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3063 - mse: 0.2909 - val_loss: 0.3140 - val_mse: 0.2990\n","Epoch 69/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3059 - mse: 0.2905 - val_loss: 0.3143 - val_mse: 0.2993\n","Epoch 70/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3060 - mse: 0.2905 - val_loss: 0.3129 - val_mse: 0.2979\n","Epoch 71/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3059 - mse: 0.2903 - val_loss: 0.3451 - val_mse: 0.3299\n","Epoch 72/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3053 - mse: 0.2899 - val_loss: 0.3166 - val_mse: 0.3016\n","Epoch 73/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3050 - mse: 0.2895 - val_loss: 0.3138 - val_mse: 0.2988\n","Epoch 74/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3050 - mse: 0.2895 - val_loss: 0.3541 - val_mse: 0.3388\n","Epoch 75/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3048 - mse: 0.2893 - val_loss: 0.3127 - val_mse: 0.2976\n","Epoch 76/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3046 - mse: 0.2889 - val_loss: 0.3135 - val_mse: 0.2982\n","Epoch 77/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3046 - mse: 0.2889 - val_loss: 0.3125 - val_mse: 0.2971\n","Epoch 78/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3041 - mse: 0.2885 - val_loss: 0.3656 - val_mse: 0.3502\n","Epoch 79/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3043 - mse: 0.2886 - val_loss: 0.3151 - val_mse: 0.2997\n","Epoch 80/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3038 - mse: 0.2879 - val_loss: 0.3155 - val_mse: 0.3001\n","Epoch 81/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3043 - mse: 0.2884 - val_loss: 0.3209 - val_mse: 0.3053\n","Epoch 82/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3036 - mse: 0.2877 - val_loss: 0.3147 - val_mse: 0.2991\n","Epoch 83/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3038 - mse: 0.2878 - val_loss: 0.3136 - val_mse: 0.2980\n","Epoch 84/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3029 - mse: 0.2870 - val_loss: 0.3303 - val_mse: 0.3147\n","Epoch 85/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3035 - mse: 0.2873 - val_loss: 0.3137 - val_mse: 0.2981\n","Epoch 86/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3031 - mse: 0.2871 - val_loss: 0.3145 - val_mse: 0.2988\n","Epoch 87/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3028 - mse: 0.2868 - val_loss: 0.3230 - val_mse: 0.3073\n","Epoch 88/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3027 - mse: 0.2866 - val_loss: 0.3648 - val_mse: 0.3490\n","Epoch 89/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3027 - mse: 0.2866 - val_loss: 0.3153 - val_mse: 0.2997\n","Epoch 90/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3024 - mse: 0.2863 - val_loss: 0.3140 - val_mse: 0.2983\n","Epoch 91/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3019 - mse: 0.2857 - val_loss: 0.3168 - val_mse: 0.3011\n","Epoch 92/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3021 - mse: 0.2859 - val_loss: 0.3148 - val_mse: 0.2990\n","Epoch 93/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3021 - mse: 0.2859 - val_loss: 0.3161 - val_mse: 0.3003\n","Epoch 94/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3019 - mse: 0.2857 - val_loss: 0.3154 - val_mse: 0.2995\n","Epoch 95/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3017 - mse: 0.2853 - val_loss: 0.3155 - val_mse: 0.2996\n","Epoch 96/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3015 - mse: 0.2852 - val_loss: 0.3158 - val_mse: 0.2998\n","Epoch 97/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3014 - mse: 0.2850 - val_loss: 0.3177 - val_mse: 0.3017\n","Epoch 98/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3010 - mse: 0.2846 - val_loss: 0.3260 - val_mse: 0.3100\n","Epoch 99/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3008 - mse: 0.2845 - val_loss: 0.3157 - val_mse: 0.2997\n","Epoch 100/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3006 - mse: 0.2842 - val_loss: 0.3144 - val_mse: 0.2984\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff4b39e0a20>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"zRA-puudhAK3","colab_type":"code","colab":{}},"source":["train_result=cnn_model.predict([train_x[train,:132],train_x[train,132:]])\n","val_result=cnn_model.predict([train_x[val,:132],train_x[val,132:]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Homo0TG8nrh1","colab_type":"code","colab":{}},"source":["train_mse=mse(train_result,train_true_y[train])\n","train_rmsle=rmsle(train_result,train_true_y[train])\n","val_mse=mse(val_result,train_true_y[val])\n","val_rmsle=rmsle(val_result,train_true_y[val])\n","train_mse_list.append(train_mse)\n","val_mse_list.append(val_mse)\n","train_rmsle_list.append(train_rmsle)\n","val_rmsle_list.append(val_rmsle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Y4EReF3hBho","colab_type":"code","outputId":"cb1cea3a-486b-4d16-e526-0b3eca24ebd9","executionInfo":{"status":"ok","timestamp":1586649858400,"user_tz":300,"elapsed":460,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_rmsle"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5462582733200518"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"pC-8XQZDpD9m","colab_type":"code","outputId":"0a5f008c-5e91-4881-c3bf-d6a5b3153321","executionInfo":{"status":"ok","timestamp":1586653135832,"user_tz":300,"elapsed":3258531,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train,val=index_list[4]\n","cnn_model=CNN(132,56,[8,32,64],[4,8,16])\n","cnn_model.compile(loss='mse', \n","                optimizer='adam',\n","                metrics=['mse'])\n","cnn_model.fit([train_x[train,:132],train_x[train,132:]],train_y[train],batch_size=2048,epochs=100,validation_data=([train_x[val,:132],train_x[val,132:]],train_y[val]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 3584)\n","Epoch 1/100\n","406/406 [==============================] - 33s 81ms/step - loss: 1.8317 - mse: 1.3804 - val_loss: 0.8209 - val_mse: 0.4127\n","Epoch 2/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.7635 - mse: 0.3924 - val_loss: 0.7064 - val_mse: 0.3693\n","Epoch 3/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.6873 - mse: 0.3771 - val_loss: 0.6476 - val_mse: 0.3627\n","Epoch 4/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.6313 - mse: 0.3670 - val_loss: 0.5991 - val_mse: 0.3547\n","Epoch 5/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.5882 - mse: 0.3605 - val_loss: 0.5639 - val_mse: 0.3522\n","Epoch 6/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.5526 - mse: 0.3544 - val_loss: 0.5289 - val_mse: 0.3438\n","Epoch 7/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.5209 - mse: 0.3473 - val_loss: 0.5017 - val_mse: 0.3394\n","Epoch 8/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4965 - mse: 0.3440 - val_loss: 0.4946 - val_mse: 0.3520\n","Epoch 9/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4743 - mse: 0.3403 - val_loss: 0.4693 - val_mse: 0.3439\n","Epoch 10/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4552 - mse: 0.3372 - val_loss: 0.4367 - val_mse: 0.3266\n","Epoch 11/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4379 - mse: 0.3343 - val_loss: 0.4253 - val_mse: 0.3283\n","Epoch 12/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4203 - mse: 0.3292 - val_loss: 0.4277 - val_mse: 0.3429\n","Epoch 13/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.4062 - mse: 0.3264 - val_loss: 0.3914 - val_mse: 0.3171\n","Epoch 14/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3938 - mse: 0.3240 - val_loss: 0.4091 - val_mse: 0.3441\n","Epoch 15/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3845 - mse: 0.3236 - val_loss: 0.3733 - val_mse: 0.3167\n","Epoch 16/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3741 - mse: 0.3208 - val_loss: 0.3637 - val_mse: 0.3143\n","Epoch 17/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3669 - mse: 0.3201 - val_loss: 0.3672 - val_mse: 0.3237\n","Epoch 18/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3588 - mse: 0.3176 - val_loss: 0.3583 - val_mse: 0.3198\n","Epoch 19/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3529 - mse: 0.3164 - val_loss: 0.3463 - val_mse: 0.3122\n","Epoch 20/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3474 - mse: 0.3148 - val_loss: 0.3557 - val_mse: 0.3251\n","Epoch 21/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3438 - mse: 0.3144 - val_loss: 0.3573 - val_mse: 0.3299\n","Epoch 22/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3394 - mse: 0.3128 - val_loss: 0.3352 - val_mse: 0.3103\n","Epoch 23/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3362 - mse: 0.3120 - val_loss: 0.3414 - val_mse: 0.3183\n","Epoch 24/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3331 - mse: 0.3107 - val_loss: 0.3312 - val_mse: 0.3097\n","Epoch 25/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3316 - mse: 0.3106 - val_loss: 0.3361 - val_mse: 0.3161\n","Epoch 26/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3288 - mse: 0.3090 - val_loss: 0.3340 - val_mse: 0.3147\n","Epoch 27/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3275 - mse: 0.3087 - val_loss: 0.3253 - val_mse: 0.3073\n","Epoch 28/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3246 - mse: 0.3066 - val_loss: 0.3213 - val_mse: 0.3042\n","Epoch 29/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3231 - mse: 0.3059 - val_loss: 0.3218 - val_mse: 0.3053\n","Epoch 30/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3227 - mse: 0.3059 - val_loss: 0.3302 - val_mse: 0.3139\n","Epoch 31/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3207 - mse: 0.3044 - val_loss: 0.3234 - val_mse: 0.3078\n","Epoch 32/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3196 - mse: 0.3039 - val_loss: 0.3216 - val_mse: 0.3062\n","Epoch 33/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3188 - mse: 0.3032 - val_loss: 0.3187 - val_mse: 0.3036\n","Epoch 34/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3179 - mse: 0.3026 - val_loss: 0.3185 - val_mse: 0.3033\n","Epoch 35/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3173 - mse: 0.3021 - val_loss: 0.3183 - val_mse: 0.3034\n","Epoch 36/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3165 - mse: 0.3015 - val_loss: 0.3180 - val_mse: 0.3035\n","Epoch 37/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3160 - mse: 0.3011 - val_loss: 0.3180 - val_mse: 0.3033\n","Epoch 38/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3155 - mse: 0.3005 - val_loss: 0.3209 - val_mse: 0.3063\n","Epoch 39/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3146 - mse: 0.2998 - val_loss: 0.3182 - val_mse: 0.3037\n","Epoch 40/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3140 - mse: 0.2992 - val_loss: 0.3174 - val_mse: 0.3029\n","Epoch 41/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3136 - mse: 0.2987 - val_loss: 0.3158 - val_mse: 0.3012\n","Epoch 42/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3135 - mse: 0.2985 - val_loss: 0.3155 - val_mse: 0.3010\n","Epoch 43/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3133 - mse: 0.2985 - val_loss: 0.3171 - val_mse: 0.3025\n","Epoch 44/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3126 - mse: 0.2977 - val_loss: 0.3166 - val_mse: 0.3021\n","Epoch 45/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3118 - mse: 0.2970 - val_loss: 0.3186 - val_mse: 0.3040\n","Epoch 46/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3116 - mse: 0.2967 - val_loss: 0.3137 - val_mse: 0.2991\n","Epoch 47/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3112 - mse: 0.2963 - val_loss: 0.3207 - val_mse: 0.3061\n","Epoch 48/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3113 - mse: 0.2964 - val_loss: 0.3158 - val_mse: 0.3013\n","Epoch 49/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3107 - mse: 0.2958 - val_loss: 0.3198 - val_mse: 0.3050\n","Epoch 50/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3103 - mse: 0.2953 - val_loss: 0.3193 - val_mse: 0.3045\n","Epoch 51/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3097 - mse: 0.2947 - val_loss: 0.3163 - val_mse: 0.3016\n","Epoch 52/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3097 - mse: 0.2948 - val_loss: 0.3180 - val_mse: 0.3032\n","Epoch 53/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3093 - mse: 0.2942 - val_loss: 0.3153 - val_mse: 0.3005\n","Epoch 54/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3088 - mse: 0.2937 - val_loss: 0.3149 - val_mse: 0.3001\n","Epoch 55/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3089 - mse: 0.2938 - val_loss: 0.3142 - val_mse: 0.2996\n","Epoch 56/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3085 - mse: 0.2933 - val_loss: 0.3142 - val_mse: 0.2993\n","Epoch 57/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3080 - mse: 0.2929 - val_loss: 0.3151 - val_mse: 0.3002\n","Epoch 58/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3079 - mse: 0.2927 - val_loss: 0.3133 - val_mse: 0.2983\n","Epoch 59/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3073 - mse: 0.2920 - val_loss: 0.3163 - val_mse: 0.3013\n","Epoch 60/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3074 - mse: 0.2921 - val_loss: 0.3156 - val_mse: 0.3006\n","Epoch 61/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3072 - mse: 0.2918 - val_loss: 0.3169 - val_mse: 0.3019\n","Epoch 62/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3069 - mse: 0.2915 - val_loss: 0.3133 - val_mse: 0.2981\n","Epoch 63/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3068 - mse: 0.2913 - val_loss: 0.3145 - val_mse: 0.2993\n","Epoch 64/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3066 - mse: 0.2911 - val_loss: 0.3146 - val_mse: 0.2994\n","Epoch 65/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3064 - mse: 0.2907 - val_loss: 0.3141 - val_mse: 0.2989\n","Epoch 66/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3060 - mse: 0.2905 - val_loss: 0.3122 - val_mse: 0.2970\n","Epoch 67/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3055 - mse: 0.2901 - val_loss: 0.3161 - val_mse: 0.3009\n","Epoch 68/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3055 - mse: 0.2899 - val_loss: 0.3156 - val_mse: 0.3003\n","Epoch 69/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3049 - mse: 0.2894 - val_loss: 0.3130 - val_mse: 0.2976\n","Epoch 70/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3051 - mse: 0.2895 - val_loss: 0.3148 - val_mse: 0.2995\n","Epoch 71/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3051 - mse: 0.2893 - val_loss: 0.3164 - val_mse: 0.3010\n","Epoch 72/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3051 - mse: 0.2893 - val_loss: 0.3195 - val_mse: 0.3041\n","Epoch 73/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3046 - mse: 0.2889 - val_loss: 0.3160 - val_mse: 0.3005\n","Epoch 74/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3045 - mse: 0.2886 - val_loss: 0.3196 - val_mse: 0.3040\n","Epoch 75/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3043 - mse: 0.2884 - val_loss: 0.3145 - val_mse: 0.2990\n","Epoch 76/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3036 - mse: 0.2878 - val_loss: 0.3132 - val_mse: 0.2976\n","Epoch 77/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3037 - mse: 0.2878 - val_loss: 0.3164 - val_mse: 0.3009\n","Epoch 78/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3034 - mse: 0.2875 - val_loss: 0.3132 - val_mse: 0.2976\n","Epoch 79/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3031 - mse: 0.2873 - val_loss: 0.3143 - val_mse: 0.2986\n","Epoch 80/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3034 - mse: 0.2874 - val_loss: 0.3148 - val_mse: 0.2991\n","Epoch 81/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3033 - mse: 0.2873 - val_loss: 0.3145 - val_mse: 0.2987\n","Epoch 82/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3026 - mse: 0.2866 - val_loss: 0.3152 - val_mse: 0.2993\n","Epoch 83/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3027 - mse: 0.2865 - val_loss: 0.3146 - val_mse: 0.2988\n","Epoch 84/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3022 - mse: 0.2862 - val_loss: 0.3125 - val_mse: 0.2966\n","Epoch 85/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3021 - mse: 0.2860 - val_loss: 0.3163 - val_mse: 0.3005\n","Epoch 86/100\n","406/406 [==============================] - 33s 80ms/step - loss: 0.3020 - mse: 0.2857 - val_loss: 0.3140 - val_mse: 0.2981\n","Epoch 87/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3020 - mse: 0.2856 - val_loss: 0.3153 - val_mse: 0.2992\n","Epoch 88/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3019 - mse: 0.2857 - val_loss: 0.3154 - val_mse: 0.2994\n","Epoch 89/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3016 - mse: 0.2854 - val_loss: 0.3120 - val_mse: 0.2961\n","Epoch 90/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3014 - mse: 0.2849 - val_loss: 0.3171 - val_mse: 0.3010\n","Epoch 91/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3017 - mse: 0.2852 - val_loss: 0.3148 - val_mse: 0.2989\n","Epoch 92/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3012 - mse: 0.2848 - val_loss: 0.3168 - val_mse: 0.3007\n","Epoch 93/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3013 - mse: 0.2849 - val_loss: 0.3149 - val_mse: 0.2988\n","Epoch 94/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3007 - mse: 0.2843 - val_loss: 0.3147 - val_mse: 0.2986\n","Epoch 95/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3010 - mse: 0.2846 - val_loss: 0.3177 - val_mse: 0.3015\n","Epoch 96/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3006 - mse: 0.2842 - val_loss: 0.3137 - val_mse: 0.2975\n","Epoch 97/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3003 - mse: 0.2840 - val_loss: 0.3145 - val_mse: 0.2983\n","Epoch 98/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3002 - mse: 0.2837 - val_loss: 0.3149 - val_mse: 0.2985\n","Epoch 99/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3004 - mse: 0.2836 - val_loss: 0.3169 - val_mse: 0.3006\n","Epoch 100/100\n","406/406 [==============================] - 32s 80ms/step - loss: 0.3001 - mse: 0.2836 - val_loss: 0.3141 - val_mse: 0.2977\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff460adeeb8>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"EuntU7u8pFqc","colab_type":"code","colab":{}},"source":["train_result=cnn_model.predict([train_x[train,:132],train_x[train,132:]])\n","val_result=cnn_model.predict([train_x[val,:132],train_x[val,132:]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNW9akn8pG2w","colab_type":"code","colab":{}},"source":["train_mse=mse(train_result,train_true_y[train])\n","train_rmsle=rmsle(train_result,train_true_y[train])\n","val_mse=mse(val_result,train_true_y[val])\n","val_rmsle=rmsle(val_result,train_true_y[val])\n","train_mse_list.append(train_mse)\n","val_mse_list.append(val_mse)\n","train_rmsle_list.append(train_rmsle)\n","val_rmsle_list.append(val_rmsle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"13t30qGspIGo","colab_type":"code","outputId":"18fc17be-db60-4c73-d24a-119b75b4ff38","executionInfo":{"status":"ok","timestamp":1586654309144,"user_tz":300,"elapsed":389,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_rmsle"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5456448186580519"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"ysRKmDkyxifK","colab_type":"code","outputId":"05797324-e5e8-4ab7-9753-caf7766d64f9","executionInfo":{"status":"ok","timestamp":1586654310897,"user_tz":300,"elapsed":345,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.mean(train_mse_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1041.6227243039853"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"RxA2Jyg1xnPX","colab_type":"code","outputId":"d7e40fc6-96a1-4ae1-adc3-d4accb1e94ff","executionInfo":{"status":"ok","timestamp":1586557227648,"user_tz":300,"elapsed":259,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.mean(train_rmsle_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5778004352760864"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"xRbRVUtoxqZJ","colab_type":"code","outputId":"a78ee81e-ecd7-4958-da0d-56858a98f04b","executionInfo":{"status":"ok","timestamp":1586557228674,"user_tz":300,"elapsed":297,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.mean(val_rmsle_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.581350693692059"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"pdQCoMgextN1","colab_type":"code","outputId":"0cc5ea28-abc6-4c6e-a775-ebe6ab4a6a23","executionInfo":{"status":"ok","timestamp":1586557229762,"user_tz":300,"elapsed":405,"user":{"displayName":"Jiarui Feng","photoUrl":"","userId":"09871538922838670524"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.mean(val_mse_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1163.0134331843622"]},"metadata":{"tags":[]},"execution_count":126}]}]}